<!DOCTYPE html>

<html lang="en-us">
<head>
  <meta name="generator" content=
  "HTML Tidy for HTML5 (experimental) for Linux https://github.com/w3c/tidy-html5/tree/68a9e74">
  <link href="getusermedia.css" rel="stylesheet" type="text/css">

  <title>Media Capture and Streams</title>
  <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
  <!--
   To publish this document, see instructions in README
   -->

  <script class="remove" src="http://www.w3.org/Tools/respec/respec-w3c-common"
  type="text/javascript">
  <!-- keep this comment -->
  </script>
  <script class="remove" src="getusermedia.js" type="text/javascript">
  <!-- keep this comment -->
  </script>
</head>

<body>
  <section id="abstract">
    <p>This document defines a set of JavaScript APIs that allow local media,
    including audio and video, to be requested from a platform.</p>
  </section>

  <section id="sotd">
    <p>This document is not complete. It is subject to major changes and, while
    early experimentations are encouraged, it is therefore not intended for
    implementation. The API is based on preliminary work done in the WHATWG.</p>
  </section>

  <section class="informative" id="intro">
    <h2>Introduction</h2>

    <p>Access to multimedia streams (video, audio, or both) from local devices
    (video cameras, microphones, Web cams) can have a number of uses, such as
    real-time communication, recording, and surveillance.</p>

    <p>This document defines the APIs used to get access to local devices that
    can generate multimedia stream data. This document also defines the MediaStream
    API by which JavaScript is able to manipulate the stream data or otherwise
    process it.</p>
  </section>

<section id="conformance">
      <p>
        This specification defines conformance criteria that apply to a single
        product: the <dfn>user agent</dfn> that implements the
        interfaces that it contains.
      </p>
      <p>
        Implementations that use ECMAScript to implement the APIs defined in
        this specification must implement them in a manner consistent with the
        ECMAScript Bindings defined in the Web IDL specification [[!WEBIDL]],
        as this specification uses that specification and terminology.
      </p>
    </section>
    <section>
      <h2>Terminology</h2>

      <dl>
        <dt><i>HTML Terms:</i></dt>
        <dd>
          <p>
            The <code><a href="http://dev.w3.org/html5/spec/webappapis.html#eventhandler">
            EventHandler</a></code> interface represents a callback used for event
            handlers as defined in [[!HTML5]].
          </p>
          <p>
            The concepts <dfn><a href="http://dev.w3.org/html5/spec/webappapis.html#queue-a-task">
            queue a task</a></dfn> and
            <dfn><a href="http://dev.w3.org/html5/spec/webappapis.html#fire-a-simple-event">
            fires a simple event</a></dfn> are defined in [[!HTML5]].
          </p>

          <p>
            The terms <dfn><a href="http://dev.w3.org/html5/spec/webappapis.html#event-handlers">
            event handlers</a></dfn> and
            <dfn><a href="http://dev.w3.org/html5/spec/webappapis.html#event-handler-event-type">
            event handler event types</a></dfn> are defined in [[!HTML5]].
          </p>
        </dd>

        <dt><dfn>source</dfn></dt>
        <dd>
          <p>A source is the "thing" providing the source of a media stream
          track. The source is the broadcaster of the media itself. A
          source can be a physical webcam, microphone, local video or
          audio file from the user's hard drive, network resource, or
          static image.</p>

          <p>Some sources have an identifier which <em title="must"
          class="rfc2119">must</em> be unique to the application
          (un-guessable by another application) and persistent between
          application sessions (e.g., the identifier for a given
          source device/application must stay the same, but not be
          guessable by another application). Sources that must have an
          identifier are camera and microphone sources; local file
          sources are not required to have an identifier. Source
          identifiers let the application save, identify the
          availability of, and directly request specific sources.</p>

          <p>Other than the identifier, other bits of source identity
          are <strong>never</strong> directly available to the
          application until the user agent connects a source to a
          track. Once a source has been "released" to the application
          (either via a permissions UI, pre-configured allow-list, or
          some other release mechanism) the application will be able
          discover additional source-specific capabilities.</p>

          <p>Sources <strong>do not</strong> have constraints --
          tracks have constraints. When a source is connected to a
          track, it must conform to the constraints present on that
          track (or set of tracks).</p>

          <p>Sources will be released (un-attached) from a track when
          the track is ended for any reason.</p>

          <p>On the <code><a>MediaStreamTrack</a></code> object,
          sources are represented by a <code><a>sourceType</a></code>
          attribute. The behavior of APIs associated with the source's
          capabilities and state change depending on the source
          type.</p>

          <p>Sources have <code><a>capabilities</a></code>
          and <code><a>state</a></code>. The capabilities and state
          are "owned" by the source and are common to any (multiple)
          tracks that happen to be using the same source (e.g., if two
          different tracks objects bound to the same source ask for
          the same capability or state information, they will get back
          the same answer).</p>
        </dd>

        <dt><dfn title="state">State (Source State)</dfn></dt>
        <dd>
          <p>State refers to the immediate, current value of the
          source's (optionally constrained) capabilities. State is
          always read-only.</p>
          <p>A source's state can change dynamically over time due to
          environmental conditions, sink configurations, or constraint
          changes. A source's state must always conform to the current
          set of mandatory constraints that all of the tracks it is
          bound to have defined, and should do its best to conform to
          the set of optional constraints specified.</p>
          <p>A source's state is directly exposed to audio and video
          track objects through individual read-only attributes. These
          attributes share the same name as their
          corresponding <a>capabilities</a>
          and <a>constraints</a>.</p>
          <p>Events are available that signal to the application that
          source state has changed.</p>
          <p>A conforming user-agent <em title="must"
          class="rfc2119">must</em> support all the state names
          defined in this spec.</p>
        </dd>

        <dt><dfn title="capabilities"
        id="dfn-capabilities">Capabilities</dfn></dt>
        <dd>
          <p>Source capabilities are the intrinsic "features" of a
          source object. For each source state, there is a
          corresponding capability that describes whether it is
          supported by the source and if so, what the range of
          supported values are. Capabilities are expressed as either a
          series of states (for enumerated-type capabilities) or as a
          min/max range.</p>
          <p>The values of the supported capabilities must be
          normalized to the ranges and enumerated types defined in
          this specification.</p>
          <p>Capabilities return the same underlying per-source
          capabilities, regardless of any user-supplied constraints
          present on the source (capabilities are independent of
          constraints).</p>
          <p>Source capabilities are effectively
          constant. Applications should be able to depend on a
          specific source having the same capabilities for any
          session.</p>
        </dd>

        <dt><dfn title="constraints"
        id="dfn-constraints">Constraints</dfn></dt>

        <dd>
          <p>Constraints are an optional feature for restricting the
          range of allowed variability on a source. Without provided
          constraints, implementations are free to select a source's
          state from the full range of its supported capabilities, and
          to adjust that state at any time for any reason.</p>

          <p>Constraints may be optional or mandatory. Optional
          constraints are represented by an ordered list, mandatory
          constraints are an unordered set. The order of the optional
          constraints is from most important (at the head of the list)
          to least important (at the tail of the list).</p>

          <p>Constraints are stored on the track object, not the
          source. Each track can be optionally initialized with
          constraints, or constraints can be added afterward through
          the constraint APIs defined in this spec.</p>

          <p>Applying track level constraints to a source is
          conditional based on the type of source. For example,
          read-only sources will ignore any specified constraints on
          the track.</p>

          <p>It is possible for two tracks that share a unique source
          to apply contradictory constraints. Under such
          contradictions, the implementation will mute both tracks and
          notify them that they are over-constrained.</p>

          <p>Events are available that allow the application to know
          when constraints cannot be met by the user agent. These
          typically occur when the application applies constraints
          beyond the capability of a source, contradictory
          constraints, or in some cases when a source cannot sustain
          itself in over-constrained scenarios (overheating,
          etc.).</p>

          <p>Constraints that are intended for video sources will be
          ignored by audio sources and vice-versa. Similarly,
          constraints that are not recognized will be preserved in the
          constraint structure, but ignored by the UA. This
          will allow future constraints to be defined in a backward
          compatible manner.</p>

          <p>A correspondingly-named constraint exists for each
          corresponding source state name and capability name.  In
          general, user agents will have more flexibility to optimize
          the media streaming experience the fewer constraints are
          applied.</p>
        </dd>
      </dl>
    </section>

  <section id="stream-api">
    <h2>MediaStream API</h2>

    <section>
      <h2>Introduction</h2>

      <p>The <code><a>MediaStream</a></code> interface is used to represent
      streams of media data, typically (but not necessarily) of audio and/or
      video content, e.g. from a local camera. The data from a
      <code><a>MediaStream</a></code> object does not necessarily have a
      canonical binary form; for example, it could just be "the video currently
      coming from the user's video camera". This allows user agents to
      manipulate media streams in whatever fashion is most suitable on the
      user's platform.</p>

      <p>Each <code><a>MediaStream</a></code> object can contain zero or more
      tracks, in particular audio and video tracks. All tracks in a MediaStream
      are intended to be synchronized when rendered. Different MediaStreams do
      not need to be synchronized.</p>

      <p>Each track in a MediaStream object has a corresponding
      <code><a>MediaStreamTrack</a></code> object.</p>

      <p>A <code><a>MediaStreamTrack</a></code> represents content comprising
      one or more channels, where the channels have a defined well known
      relationship to each other (such as a stereo or 5.1 audio signal).</p>

      <p>A channel is the smallest unit considered in this API
      specification.</p>

      <p>A <code><a>MediaStream</a></code> object has an input and an output.
      The input depends on how the object was created: a
      <code><a>MediaStream</a></code> object generated by a <code><a href=
      "#dom-navigator-getusermedia">getUserMedia()</a></code> call (which is
      described later in this document), for instance, might take its input
      from the user's local camera. The output of the object controls how the
      object is used, e.g., what is saved if the object is written to a file or
      what is displayed if the object is used in a <code>video</code>
      element.</p>

      <p>Each track in a <code><a>MediaStream</a></code> object can be
      disabled, meaning that it is muted in the object's output. All tracks are
      initially enabled.</p>

      <p>A <code><a>MediaStream</a></code> can be <a>finished</a>, indicating
      that its inputs have forever stopped providing data.</p>

      <p>The output of a <code><a>MediaStream</a></code> object MUST correspond
      to the tracks in its input. Muted audio tracks MUST be replaced with
      silence. Muted video tracks MUST be replaced with blackness.</p>

      <p>A new <code><a>MediaStream</a></code> object can be created from
      accessible media sources (that does not require any additional
      permissions) using the <code><a href="#dom-mediastream">MediaStream()</a>
      </code> constructor. The constructor argument can either be an existing
      <code><a>MediaStream</a></code> object, in which case all the tracks of
      the given stream are added to the new <code><a>MediaStream</a></code>
      object, or an array of <code><a>MediaStreamTrack</a></code> objects. The
      latter form makes it possible to compose a stream from different source
      streams.</p>

      <p><img alt="A MediaStream" src="images/media-stream.png" width=
      "418"></p>

      <p>Both <code><a>MediaStream</a></code> and <code>
      <a>MediaStreamTrack</a></code> objects can be cloned. This allows for
      greater control since the separate instances can be manipulated and
      <a title="consumer">consumed</a> individually. A cloned <code>
      <a>MediaStream</a></code> contains clones of all member tracks from the
      original stream.</p>

      <p>When a <code><a>MediaStream</a></code> object is being generated
      from a local file (as opposed to a live audio/video source), the user
      agent SHOULD stream the data from the file in real time, not all at once.
      The <code>MediaStream</code> object is also used in contexts outside
      <code>getUserMedia</code>, such as [[!WEBRTC10]]. In both cases, ensuring
      a realtime stream reduces the ease with which pages can distinguish live
      video from pre-recorded video, which can help protect the user's
      privacy.</p>
    </section>

    <section>
      <h2>MediaStream</h2>

      <p>The <dfn id="dom-mediastream"> <code>MediaStream()</code></dfn>
      constructor composes a new stream out of existing tracks. It takes an
      optional argument of type <code><a>MediaStream</a></code> or an array of
      <code><a>MediaStreamTrack</a></code> objects. <dfn id='mediastream-constructor'>When the constructor is
      invoked</dfn>, the UA must run the following steps:</p>

      <ol>
        <li>
          <p>Let <var>stream</var> be a newly constructed <code>
          <a>MediaStream</a></code> object.</p>
        </li>

        <li>
          <p>Initialize <var>stream's</var> <code><a href=
          "#dom-mediastream-id">id</a></code> attribute to a newly generated
          value.</p>
        </li>

        <li>
          <p>If the constructor's argument is present, run the sub steps that
          corresponds to the argument type.</p>

          <ul>
            <li>
              <p><code>Array</code> of <code><a>MediaStreamTrack</a></code>
              objects:</p>

              <p>Run the following sub steps for each <code>
              <a>MediaStreamTrack</a></code> in the array:</p>

              <ol>
                <li>
                  <p><em>Add track</em>: Let <var>track</var> be the <code>
                  <a>MediaStreamTrack</a></code>  about to be processed.</p>
                </li>

                <li>
                  <p>If <var>track</var> has <a href="#track-ended">ended</a>, then abort these
                  steps and continue with the next track (if any).</p>
                </li>

                <li>
                  <p>Add <var>track</var> to <var>stream</var>'s <a href=
                  "#track-set">track set</a>.</p>
                </li>
              </ol>

            </li>

            <li>
              <p><code><a>MediaStream</a></code>:</p>

              <p>Run the sub steps labeled <em>Add track</em> (above) for every
              <code><a>MediaStreamTrack</a></code> in the argument stream's
              <a href="#track-set">track set</a>.
              </p>
            </li>
          </ul>
        </li>

        <li>
          <p>If <var>stream</var>'s <a href="#track-set">track set</a> is
          empty, set <var>stream</var>'s <code><a href=
          "#dom-mediastream-inactive">inactive</a></code> attribute to
          <code>true</code>, otherwise set it to <code>false</code>.</p>
        </li>

        <li>
          <p>Return <var>stream</var>.</p>
        </li>
      </ol>

      <p>A <code><a>MediaStream</a></code> can have multiple audio and video
      sources (e.g. because the user has multiple microphones, or because the
      real source of the stream is a media resource with many media tracks).
      The stream represented by a <code><a>MediaStream</a></code> thus has zero
      or more tracks.</p>

      <p>The tracks of a <code><a>MediaStream</a></code> are stored in a
      <dfn id="track-set">track set</dfn>. The track set MUST contain the
      <code><a>MediaStreamTrack</a></code> objects that correspond
      to the tracks of the stream. The relative order of the tracks in the set
      is user agent defined and the API will never put any requirements on the
      order. The proper way to find a specific <code><a>MediaStreamTrack</a>
      </code> object in the set is to look it up by its
      <code><a href="#dom-mediastreamtrack-id">id</a></code>.</p>

      <p>An object that reads data from the output of a
      <code><a>MediaStream</a></code> is referred to as a
      <code><a>MediaStream</a></code> <dfn>consumer</dfn>. The list of
      <code><a>MediaStream</a></code> consumers currently include the media
      elements [[!HTML5]], <code>RTCPeerConnection</code> [[!WEBRTC10]],
      <code>MediaRecorder</code> [[!mediastream-rec]] and
      <code>ImageCapture</code> [[!mediastream-imagecap]].</p>

      <p class="note"><code><a>MediaStream</a></code> consumers must be able to
      handle tracks being added and removed. This behavior is specified per
      consumer.</p>

      <p>A <code><a>MediaStream</a></code> object is said to be
      <dfn id="stream-inactive">inactive</dfn> when it does not have any tracks
      or all tracks belonging to the stream have <a href="#track-ended">ended</a>. Otherwise the
      stream is active. A <code><a>MediaStream</a></code> can start its life as
      inactive if it is constructed without any tracks.</p>

      <p>When a <code><a>MediaStream</a></code> goes from being active to
      inactive, the user agent MUST queue a task that sets the object's
      <code><a href="#dom-mediastream-inactive">inactive</a></code> attribute
      to <code>true</code> and fire a simple event named <code><a href=
      "#event-mediastream-inactive">inactive</a></code> at the object. When a
      <code><a>MediaStream</a></code> goes from being inactive to active, the
      user agent MUST queue a task that sets the object's <code><a href=
      "#dom-mediastream-inactive">inactive</a></code> attribute to
      <code>false</code> and fire a simple event named <code><a href=
      "#event-mediastream-active">active</a></code> at the object.</p>

      <p>If the stream's activity status changed due to a user request, the task
      source for this <span title="concept-task">task</span> is the user
      interaction task source. Otherwise the task source for this <span title=
      "concept-task">task</span> is the networking task source.</p>

      <dl class="idl"
        title="interface MediaStream : EventTarget">
     <dt>Constructor()</dt>
     <dd>See the <a href="#mediastream-constructor">MediaStream constructor algorithm</a></dd>
    <dt>Constructor(MediaStream stream)</dt>
     <dd>See the <a href="#mediastream-constructor">MediaStream constructor algorithm</a></dd>
    <dt>Constructor(sequence&lt;MediaStreamTrack> tracks)</dt>
     <dd>See the <a href="#mediastream-constructor">MediaStream constructor algorithm</a></dd>
    <dt>readonly attribute DOMString id</dt>

        <dd>
          <p>When a <code><a>MediaStream</a></code> object is created, the
          user agent MUST generate a globally unique identifier string, and
          MUST initialize the object's <code><a href=
          "#dom-mediastream-id">id</a></code> attribute to that string.
          Such strings MUST only use characters in the ranges U+0021, U+0023 to
          U+0027, U+002A to U+002B, U+002D to U+002E, U+0030 to U+0039, U+0041
          to U+005A, U+005E to U+007E, and MUST be 36 characters long.</p>
          <!-- UUIDs have 36 characters
      including hyphens; the ranges above comes from RFC4574 (the a=label:
      thing in SDP) -->
          <!-- described below -->

          <p>The <dfn id="dom-mediastream-id"><code>id</code></dfn>
          attribute MUST return the value to which it was initialized when the
          object was created.</p>
        </dd>

        <dt>sequence&lt;MediaStreamTrack&gt; getAudioTracks()</dt>

        <dd>
          <p>Returns a sequence of <code><a>MediaStreamTrack</a></code> objects
          representing the audio tracks in this stream.</p>

          <p>The <dfn id=
          "dom-mediastream-getaudiotracks"><code>getAudioTracks()</code></dfn>
          method MUST return a sequence that represents a snapshot of all the
          <code><a>MediaStreamTrack</a></code> objects in this stream's
          <a href="#track-set">track set</a> whose <code>
          <a href="#dom-mediastreamtrack-kind">kind</a></code> is equal to
          "<code>audio</code>". The conversion from the <a href=
          "#track-set">track set</a> to the sequence is user agent defined and
          the order does not have to stable between calls.</p>
        </dd>

        <dt>sequence&lt;MediaStreamTrack&gt; getVideoTracks()</dt>

        <dd>
          <p>Returns a sequence of <code><a>MediaStreamTrack</a></code> objects
          representing the video tracks in this stream.</p>

          <p>The <dfn id=
          "dom-mediastream-getvideotracks"><code>getVideoTracks()</code></dfn>
          method MUST return a sequence that represents a snapshot of all the
          <code><a>MediaStreamTrack</a></code> objects in this stream's
          <a href="#track-set">track set</a> whose <code>
          <a href="#dom-mediastreamtrack-kind">kind</a></code> is equal to
          "<code>video</code>". The conversion from the <a href=
          "#track-set">track set</a> to the sequence is user agent defined and
          the order does not have to stable between calls.</p>
        </dd>

        <dt>MediaStreamTrack? getTrackById(DOMString trackId)</dt>

        <dd>
          <p>The <dfn id=
          "dom-mediastream-gettrackbyid"><code>getTrackById()</code></dfn>
          method MUST return the first <code><a>MediaStreamTrack</a></code>
          object in this stream's <a href="#track-set">track set</a> whose
          <code><a href="#dom-mediastreamtrack-id">id</a></code> is equal to
          <var>trackId</var>. The method MUST return null if no track matches
          the <var>trackId</var> argument.</p>
        </dd>

        <dt>void addTrack(MediaStreamTrack track)</dt>

        <dd>
          <p>Adds the given <code><a>MediaStreamTrack</a></code> to this
          <code><a>MediaStream</a></code>.</p>

          <p>When the <dfn id=
          "dom-mediastream-addtrack"><code>addTrack()</code></dfn> method is
          invoked, the user agent MUST run the following steps:</p>

          <ol>
            <li>
              <p>Let <var>track</var> be the <code><a>MediaStreamTrack</a>
              </code> argument and <var>stream</var> this <code><a>MediaStream</a></code>
              object.</p>
            </li>

            <li>
              <p>If <var>stream</var> is <a>finished</a>, throw an
              <code>INVALID_STATE_ERR</code> exception.</p>
            </li>

            <li>
              <p>If <var>track</var> is already in <var>stream's</var>
              <a href="#track-set">track set</a>, then abort these steps.</p>
            </li>

            <li>
              <p>Add <var>track</var> to <var>stream</var>'s <a href=
              "#track-set">track set</a>.</p>
            </li>
          </ol>
        </dd>

        <dt>void removeTrack(MediaStreamTrack track)</dt>

        <dd>
          <p>Removes the given <code><a>MediaStreamTrack</a></code> from this
          <code><a>MediaStream</a></code>.</p>

          <p>When the <dfn id=
          "dom-mediastream-removetrack"><code>removeTrack()</code></dfn> method
          is invoked, the user agent MUST run the following steps:</p>

          <ol>
            <li>
              <p>Let <var>track</var> be the <code><a>MediaStreamTrack</a>
              </code> argument and <var>stream</var> this <code><a>MediaStream</a></code>
              object.</p>
            </li>

            <li>
              <p>If <var>stream</var> is <a>finished</a>, throw an
              <code>INVALID_STATE_ERR</code> exception.</p>
            </li>

            <li>
              <p>If <var>track</var> is in <var>stream</var>'s
              <a href="#track-set">track set</a>, remove it.</p>
            </li>
          </ol>
        </dd>

        <dt>MediaStream clone()</dt>

        <dd>
          <p>Clones the given <code><a>MediaStream</a></code> and all its
            tracks.</p>

            <p>When the <dfn id=
            "dom-mediastream-clone"><code>clone()</code></dfn> method
            is invoked, the user agent MUST run the following steps:</p>

            <ol>
              <li>
                <p>Let <var>streamClone</var> be a newly constructed <code>
                <a>MediaStream</a></code> object.</p>
              </li>

              <li>
                <p>Initialize <var>streamClone</var>'s <code><a href=
                "#dom-mediastream-id">id</a></code> attribute to a newly
                generated value.</p>
              </li>

              <li>
                <p>Let <var>trackSetClone</var> be a list that contains the
                result of running
                <code><a href="#dom-mediastreamtrack-clone"
                >MediaStreamTrack.clone()</a></code> on all the tracks in this
                stream.</p>
              </li>

              <li>
                <p>Let <var>trackSetClone</var> be <var>streamClone</var>'s
                <a href="#track-set">track set</a>.</p>
              </li>
            </ol>
        </dd>

        <dt>readonly attribute boolean inactive</dt>

        <dd>
          <p>The <dfn id=
          "dom-mediastream-inactive"><code>MediaStream.inactive</code></dfn>
          attribute returns true if the <code><a>MediaStream</a></code> is
          <a href="#stream-inactive">inactive</a>, and false otherwise.</p>

          <p>When a <code><a>MediaStream</a></code> object is created, its
          <code><a href="#dom-mediastream-inactive">inactive</a></code>
          attribute MUST be set to false, unless stated otherwise (for example
          by the <code><a href="#dom-mediastream">MediaStream()</a></code>
          constructor algorithm).</p>
        </dd>

        <dt>attribute EventHandler onactive</dt>

        <dd>This event handler, of type <code><a href=
        "#event-mediastream-active">active</a></code>, MUST be supported by
        all objects implementing the <code><a>MediaStream</a></code>
        interface.</dd>

        <dt>attribute EventHandler oninactive</dt>

        <dd>This event handler, of type <code><a href=
        "#event-mediastream-inactive">inactive</a></code>, MUST be supported by
        all objects implementing the <code><a>MediaStream</a></code>
        interface.</dd>

        <dt>attribute EventHandler onaddtrack</dt>

        <dd>This event handler, of type <code><a href=
        "#event-mediastream-addtrack">addtrack</a></code>, MUST be supported by
        all objects implementing the <code><a>MediaStream</a></code> interface.
        </dd>

        <dt>attribute EventHandler onremovetrack</dt>

        <dd>This event handler, of type <code><a href=
        "#event-mediastream-removetrack">removetrack</a></code>, MUST be
        supported by all objects implementing the <code><a>MediaStream</a>
        </code> interface.</dd>
      </dl>
    </section>

    <section>
      <h2>MediaStreamTrack</h2>

      <p>A <code><a>MediaStreamTrack</a></code> object represents a media
      source in the user agent. Several <code><a>MediaStreamTrack</a></code>
      objects can represent the same media source, e.g., when the user chooses
      the same camera in the UI shown by two consecutive calls to
      <code><a href="#dom-navigator-getusermedia">getUserMedia()</a></code>
      .</p>

      <p>Note that a web application can revoke all given permissions
      with <code><a href=
      "#dom-mediastreamtrack-stop">MediaStreamTrack.stop()</a></code>.</p>

      <section>
        <h3>Life-cycle and Media Flow</h3>

        <p>A <code><a>MediaStreamTrack</a></code> has three stages in its
        lifecycle; <code>new</code>, <code>live</code> and <code>ended</code>.
        A track begins as <code>new</code> prior to being connected to an
        active source.</p>

        <p>Once connected, the <code><a href="#event-mediastreamtrack-started"
        >started</a></code> event fires and the track
        becomes <code>live</code>. In the <code>live</code> state, the track is
        active and media is available for rendering at a <code>
        <a>MediaStream</a></code> <a>consumer</a>.</p>

        <p>A muted or disabled <code><a>MediaStreamTrack</a></code> renders either
        silence (audio), black frames (video), or a zero-information-content
        equivalent. For example, a video element sourced by a muted or disabled
        <code><a>MediaStreamTrack</a></code> (contained within a
        <code><a>MediaStream</a></code>), is playing but the rendered content
        is the muted output.

        <p>The muted/unmuted state of a track reflects if the source
        provides any media at this moment. The enabled/disabled state is under
        application control and determines if the track outputs media (to its
        consumers). Hence, media from the source only flows when a <code>
        <a>MediaStreamTrack</a></code> object is both unmuted and enabled.</p>

        <p>A <code><a>MediaStreamTrack</a></code> is <dfn id=
        "track-muted">muted</dfn> when the source is temporarily unable to
        provide the track with data. A track can be muted by a user. Often this
        action is outside the control of the application. This could be as a
        result of the user hitting a hardware switch, or toggling a control in
        the operating system or browser chrome. A track can also be muted by the
        user agent. For example, a track that is a member of a <code>
        <a>MediaStream</a></code>, received via a <code><a>RTCPeerConnection</a>
        </code> [[!WEBRTC10]], is muted if the application on the other side
        disables the corresponding track in the <code>MediaStream</code> being
        sent.</p>

        <p>Applications are able to <dfn id="track-enabled">enable</dfn> or
        disable a <code><a>MediaStreamTrack</a></code> to prevent it from
        rendering media from the source. A muted track will however, regardless
        of the enabled state, render silence and blackness. A disabled track is
        logically equivalent to a muted track, from a consumer point of view.
        </p>

        <p>For a newly created <code><a>MediaStreamTrack</a></code> object, the
        following applies. The track is always enabled unless stated otherwise
        (for examlpe when cloned) and the muted state reflects the state of the
        source at the time the track is created.</p>

        <p>A <code><a>MediaStreamTrack</a></code> object is said to <em>end</em>
        when the source of the track is disconnected or exhausted.</p>

        <p>When a <code><a>MediaStreamTrack</a></code> object ends for any reason
        (e.g., because the user rescinds the permission for the page to use the
        local camera, or because the data comes from a finite file and the file's
        end has been reached and the user has not requested that it be looped, or
        because the UA has instructed the track to end for any reason, or because
        the reference count of the track's underlying media source has reached
        zero), it is said to be <dfn id="track-ended">ended</dfn>. When track instance
        <var>track</var> ends for any reason other than the <code><a href=
        "#dom-mediastreamtrack-stop">stop()</a></code> method being invoked on the
        <code><a>MediaStreamTrack</a></code> object that represents
        <var>track</var>, the user agent MUST queue a task that runs the
        following steps:</p>

        <ol>
          <li>
            <p>If the track's <code><a href=
            "#dom-mediastreamtrack-readystate">readyState</a></code> attribute
            has the value <code>ended</code> already, then abort these steps.
            (The <code><a href="#dom-mediastreamtrack-stop">stop()</a></code>
            method was probably called just before the track stopped for other
            reasons.)</p>
          </li>

          <li>
            <p>Set <var>track's</var> <code><a href=
            "#dom-mediastreamtrack-readystate">readyState</a></code> attribute to
            <code>ended</code>.</p>
          </li>

          <li>
            <p>Fire a simple event named <code><a href=
            "#event-mediastreamtrack-ended">ended</a></code> at the object.</p>
          </li>
        </ol>

        <p>If the end of the stream was reached due to a user request, the event
        source for this event is the user interaction event source.</p>
      </section>

      <section>
        <h3>Tracks and Constraints</h3>

        <p>Constraints are independent of sources.  However, if
        the <code><a>sourceType</a></code> is "none",
        the <code><a>readonly</a></code> attribute
        is <code>true</code>, or the <code><a>remote</a></code>
        attribute is <code>true</code>, the track's constraints will
        not be applied to the source.</p>

        <p>Whether <code><a>MediaTrackConstraints</a></code> were provided at
        track initialization time or need to be established later at
        runtime, the APIs defined below allow the retrieval and
        manipulation of the constraints currently established on a
        track.</p>

        <p>Each track maintains an internal version of
        the <code><a>MediaTrackConstraints</a></code> structure, namely a
        mandatory set of constraints (no duplicates), and an optional
        ordered list of individual constraint objects (may contain
        duplicates). The internal stored constraint structure is only
        exposed to the application using the existing
        <code><a>MediaTrackConstraints</a></code>,
        <code><a>MediaTrackConstraintSet</a></code>, <code><a>MediaTrackConstraint</a></code>,
        and similarly-derived-type dictionary objects.</p>

        <p>When track constraints change, a user agent <em title="must"
        class="rfc2119">must</em> queue a task to evaluate those changes
        when the task queue is next serviced. Similarly, if
        the <a href="#widl-MediaSourceStates-sourceType"><code>sourceType</code></a>
        changes, then the user agent should perform the same actions to
        re-evaluate the constraints of each track affected by that
        source change.</p>
      </section>

      <section>
        <h3>Interface Definition</h3>
        


        <dl class="idl" title="interface MediaStreamTrack : EventTarget">

          <dt>readonly attribute DOMString kind</dt>

          <dd>
            <p>The <dfn id=
            "dom-mediastreamtrack-kind"><code>MediaStreamTrack.kind</code></dfn>
            attribute MUST return the string "<code>audio</code>" if the object
            represents an audio track or "<code>video</code>" if object represents
            a video track.</p>
          </dd>

          <dt>readonly attribute DOMString id</dt>

          <dd>
            <p>Unless a <code><a>MediaStreamTrack</a></code> object is created as
            a part a of special purpose algorithm that specifies how the track id
            must be initialized, the user agent MUST generate a globally unique
            identifier string and initialize the object's <code><a href=
            "#dom-mediastreamtrack-id">id</a></code> attribute to that string.</p>

            <p>An example of an algorithm that specifies how the track id must be
            initialized is the algorithm to represent an incoming network
            component with a <code><a>MediaStreamTrack</a></code> object.
            [[!WEBRTC10]]</p>

            <p><dfn id="dom-mediastreamtrack-id">
            <code>MediaStreamTrack.id</code></dfn> attribute MUST return the value
            to which it was initialized when the object was created.</p>
          </dd>

          <dt>readonly attribute DOMString label</dt>

          <dd>
            <p>User agents MAY label audio and video sources (e.g., "Internal
            microphone" or "External USB Webcam"). The <dfn id=
            "dom-mediastreamtrack-label"><code>MediaStreamTrack.label</code></dfn>
            attribute MUST return the label of the object's corresponding track,
            if any. If the corresponding track has or had no label, the attribute
            MUST instead return the empty string.</p>

            <p class="note">Thus the <code><a href=
            "#dom-mediastreamtrack-kind">kind</a></code> and <code title=
            "dom-MediaStreamTrack-label"><a href=
            "#dom-mediastreamtrack-label">label</a></code> attributes do not
            change value, even if the <code><a>MediaStreamTrack</a></code> object
            is disassociated from its corresponding track.</p>
          </dd>

          <dt>attribute boolean enabled</dt>

          <dd>
            <p>The <dfn id=
            "dom-mediastreamtrack-enabled"><code>MediaStreamTrack.enabled</code></dfn>
            attribute, on getting, MUST return the last value to which it was
            set. On setting, it MUST be set to the new value, and then, if the
            <code><a>MediaStreamTrack</a></code> object is still associated with
            a track, MUST enable the track if the new value is true, and disable
            it otherwise.</p>

            <p class="note">Thus, after a <code><a>MediaStreamTrack</a></code> is
            disassociated from its track, its <code><a href=
            "#dom-mediastreamtrack-enabled">enabled</a></code> attribute still
            changes value when set; it just doesn't do anything with that new
            value.</p>
          </dd>

          <dt>readonly attribute boolean muted</dt>

          <dd>
            <p>The <dfn id=
            "dom-mediastreamtrack-muted"><code>MediaStreamTrack.muted</code></dfn>
            attribute MUST return <code>true</code> if the track is <a href=
            "#track-muted">muted</a>, and <code>false</code> otherwise.</p>
          </dd>

          <dt>attribute EventHandler onmute</dt>

          <dd>This event handler, of type <code><a href=
          "#event-mediastreamtrack-mute">mute</a></code>, MUST be supported by
          all objects implementing the <code><a>MediaStreamTrack</a></code>
          interface.</dd>

          <dt>attribute EventHandler onunmute</dt>

          <dd>This event handler, of type <code><a href=
          "#event-mediastreamtrack-unmute">unmute</a></code>, MUST be supported by
          all objects implementing the <code><a>MediaStreamTrack</a></code>
          interface.</dd>

          <dt>readonly attribute boolean _readonly</dt>

          <dd>
            If the track (audio or video) is backed by a read-only
            source such as a file, or the track source is a local
            microphone or camera, but is shared so that constraints applied to
            the track cannot modify the source's state, the <dfn id=
            "dom-mediastreamtrack-readonly"><code>readonly</code></dfn>
            attribute MUST return the value <code>true</code>.
            Otherwise, it must return the value <code>false</code>.
          </dd>

          <dt>readonly attribute boolean remote</dt>

          <dd>
            If the track is sourced by
            an <code>RTCPeerConnection</code>, the <dfn id=
            "dom-mediastreamtrack-remote"><code>remote</code></dfn>
            attribute MUST return the value <code>true</code>.
            Otherwise, it must return the value <code>false</code>.
          </dd>

          <dt>readonly attribute MediaStreamTrackState readyState</dt>

          <dd>
            <p>The <dfn id=
            "dom-mediastreamtrack-readystate"><code>readyState</code></dfn>
            attribute represents the state of the track. It MUST return the value
            to which the user agent last set it.</p>
          </dd>

          <dt>attribute EventHandler onstarted</dt>

          <dd>This event handler, of type <code><a href=
          "#event-mediastreamtrack-started">started</a></code>, MUST be supported by
          all objects implementing the <code><a>MediaStreamTrack</a></code>
          interface.</dd>

          <dt>attribute EventHandler onended</dt>

          <dd>This event handler, of type <code><a href=
          "#event-mediastreamtrack-ended">ended</a></code>, MUST be supported by
          all objects implementing the <code><a>MediaStreamTrack</a></code>
          interface.</dd>

          <dt>static void getSources(SourceInfoCallback resultCallback)</dt>

          <dd>
            <p>The static <dfn id="dom-mediastreamtrack-getsources">
            <code>getSources()</code></dfn> method collects authorized
            information for all available sources.</p>
          </dd>



          <dt>MediaStreamTrack clone()</dt>

          <dd>
            <p>Clones the given <code><a>MediaStreamTrack</a></code>.</p>

            <p>When the <dfn id=
            "dom-mediastreamtrack-clone"><code>clone()</code></dfn> method
            is invoked, the user agent MUST run the following steps:</p>

            <ol>
              <li>
                <p>Let <var>trackClone</var> be a newly constructed <code>
                <a>MediaStreamTrack</a></code> object.</p>
              </li>

              <li>
                <p>Initialize <var>trackClone</var>'s <code><a href=
                "#dom-mediastreamtrack-id">id</a></code> attribute to a newly
                generated value.</p>
              </li>

              <li>
                <p>Let <var>trackClone</var> inherit this track's underlying
                source, <code>
                <a href="#dom-mediastreamtrack-kind">kind</a></code>, <code>
                <a href="#dom-mediastreamtrack-label">label</a></code> and
                <a href="#dom-mediastreamtrack-enabled">enabled</a></code>
                attributes.</p>
              </li>

              <li>
                <p>Return <var>trackClone</var>.</p>
              </li>
            </ol>
          </dd>

          <dt>void stop ()</dt>

          <dd>
            <p>When a <code><a>MediaStreamTrack</a></code>
            object's <dfn id=
            "dom-mediastreamtrack-stop"><code>stop()</code></dfn> method
            is invoked, the user agent MUST run following steps:</p>

            <ol>
              <li>
                <p>Let <var>track</var> be the current
                <code><a>MediaStreamTrack</a></code> object.</p>
              </li>

              <li>
                <p>If <var>track</var> has no source attached
                (<code><a>sourceType</a></code> is "none") or if the source is
                provided by an <code>RTCPeerConnection</code>, then abort these
                steps.</p>
              </li>

              <li>
                <p>Set <var>track's</var> <code><a href=
                "#dom-mediastreamtrack-readystate">readyState</a></code>
                attribute to <code>ended</code>.</p>
              </li>

              <li>
                <p>Permanently stop the generation of data for <var>track</var>'s
                source. If the data is being generated from a live source (e.g.,
                a microphone or camera), then the user agent SHOULD remove any
                active "on-air" indicator for that source. If the data is being
                generated from a prerecorded source (e.g. a video file), any
                remaining content in the file is ignored.</p>

                <p class="note">This will effectively
                <a href="#track-ended">end</a> all other
                <code><a>MediaStreamTrack</a></code> objects sharing the same
                source as <var>track</var>.</p>
              </li>
            </ol>

            <p>The task source for the <span title="concept-task">tasks</span>
            queued for the <code><a href=
            "#dom-mediastreamtrack-stop">stop()</a></code> method is the DOM
            manipulation task source.</p>
          </dd>
        </dl>
        
 

        <dl class='idl' title='enum MediaStreamTrackState'>
          <dt>new</dt>

          <dd>The track type is new and has not been initialized
            (connected to a source of any kind). This state implies that
            the track's label will be the empty string.</dd>

          <dt>live</dt>

          <dd>
            <p>The track is active (the track's underlying media source is making
            a best-effort attempt to provide data in real time).</p>

            <p>The output of a track in the <code>live</code> state can be
            switched on and off with the <code><a href=
            "#dom-mediastreamtrack-enabled">enabled</a></code> attribute.</p>
          </dd>

          <dt>ended</dt>

          <dd>
            <p>The track has <a href="#track-ended">ended</a> (the track's underlying media source is
            no longer providing data, and will never provide more data for this
            track).  Once a track enters this state, it never exits it.</p>

            <p>For example, a video track in a
            <code><a>MediaStream</a></code> ends if the user unplugs the
            USB web camera that acts as the track's media source.</p>
          </dd>
        </dl>
        
 <div class="idl" title="MediaStreamTrack implements Constrainable"></div>
      </section>

      <section>
        <h2>Track Source Types</h2>

        <dl class="idl" title="enum SourceTypeEnum">
	  
          <dt>none</dt>

	  <dd>This track has no source. This is the case when the
	  track is in the <code>"new"</code> or <code>"ended"</code>
	  <code><a>readyState</a></code>.</dd>

          <dt>camera</dt>

	  <dd>A valid source type only for
	  <code><a>VideoStreamTrack</a></code>s. The source is a local
	  video-producing camera source.</dd>

          <dt>microphone</dt>

	  <dd>A valid source type only for
	  <code><a>AudioStreamTrack</a></code>s. The source is a local
	  audio-producing microphone source.</dd>
	  
        </dl>
      </section>

      <section>
        <h2>Source Info</h2>
 
        <dl class="idl" title=
        "callback SourceInfoCallback = void">
          <dt>sequence&lt;SourceInfo&gt; sourceInfoList</dt>

          <dd>A sequence of <code><a>SourceInfo</a></code> objects representing
          the result of a call to <code><a href=
          "#dom-mediastreamtrack-getsources"
          >MediaStreamTrack.getSources()</a></code>.</dd>
        </dl>

        <dl class="idl" title="dictionary SourceInfo">
	  
          <dt>DOMString sourceId</dt>
	  
          <dd>The unique id for this source as described in the
          <code><a>MediaSourceStates</a></code> dictionary.</dd>

          <dt>DOMString kind</dt>
          <dd>MUST be either "audio" or "video".</dd>

          <dt>DOMString label</dt>
          <dd>If the application is authorized to get info from this
          source, the <code>label</code> attribute will be filled in
          with exactly the same value as would have been returned from
          a call to <code><a>getUserMedia()</a></code> with a
          constraint specifying this
          source's <code><a>sourceId</a></code>.</dd>
        </dl>
      </section>

      <section>
        <h2>Video Facing Mode Enum</h2>

        <dl class="idl" title="enum VideoFacingModeEnum">
          <dt>user</dt>
          <dd>The source is facing toward the user (a self-view camera).</dd>

          <dt>environment</dt>
          <dd>The source is facing away from the user (viewing the
          environment).</dd>

          <dt>left</dt>
          <dd>The source is facing to the left of the user.</dd>

          <dt>right</dt>
          <dd>The source is facing to the right of the user.</dd>
        </dl>
      </section>

      <section>
        <h2>Isolated Media Streams</h2>
        
        <p>When either the "noaccess" or "peerIdentity" constraints is
          applied to a MediaStreamTrack, the track shall be isolated so that its
          content is not accessible to the content JS. An isolated media stream
          may be used for two purposes:
        </p>
        <ul>
          <li>
            <p>
              Displayed in an appropriate tag (e.g., a video or audio element).
              The video element MUST have a unique origin so that it is
              inaccessible to the content JS. This is the same security mechanism
              as is used with an ordinary audio or video element which has
              a src= property from a separate origin.
            </p>
          </li>
          <li>
            <p>
              Used as the argument to addStream() for a PeerConnection, subject
              to the restrictions detailed in the WebRTC document.
            </p>
          </li>
        </ul>
        <p>
          When the noaccess=true constraint applies to a track, that track
          may be added to any PeerConnection.
        </p>

        <p class="note"> Open Issue: The editors worry that the above paragraph
        is just wrong. If the track can be added to a PeerConnection that
        is connect to another PeerConenction in the same application, the
        application could get access to the data. We sugest this should be changed
        from "may be added" to "may not be added". This will allow noaccess=true
        to be used for things like hair check dialogs. 
        </p>
        
        <p>
          When the peerIdentity=foo constraint applies to a track, then
          that track may be added only to PeerConnections with compatible
          peer identities as described in the WebRTC document.
        </p>

        <p>
          Both the noaccess and peerIdentity constraints must be mandatory.
          Any use of them in the optional block must trigger an error.
        </p>
      </section>
    </section>

    <section>
      <h3>MediaStreamTrackEvent</h3>

      <p>The <code><a href=
      "#event-mediastream-addtrack">addtrack</a></code> and
      <code title="event-MediaStreamTracklist-removetrack"><a href=
      "#event-mediastream-removetrack">removetrack</a></code> events
      use the <code><a>MediaStreamTrackEvent</a></code> interface.</p>

      <p><dfn title="Fire a track event">Firing a track event named
      <var>e</var></dfn> with a <code><a>MediaStreamTrack</a></code>
      <var>track</var> means that an event with the name <var>e</var>, which
      does not bubble (except where otherwise stated) and is not cancelable
      (except where otherwise stated), and which uses the
      <code><a>MediaStreamTrackEvent</a></code> interface with the
      <code><a href="#dom-mediastreamtrackevent-track">track</a></code>
      attribute set to <var>track</var>, MUST be created and dispatched at the
      given target.</p>

      <dl class="idl" data-merge="MediaStreamTrackEventInit" title=
      "interface MediaStreamTrackEvent : Event">
	<dt>Constructor(DOMString type, MediaStreamTrackEventInit eventInitDict)</dt>
	<dd></dd>
      <dt>readonly attribute MediaStreamTrack track</dt>

        <dd>
          <p>The <dfn id=
          "dom-mediastreamtrackevent-track"><code>track</code></dfn> attribute
          represents the <code><a>MediaStreamTrack</a></code> object associated
          with the event.</p>
        </dd>
      </dl>

      <dl class="idl" title="dictionary MediaStreamTrackEventInit : EventInit">
        <dt>MediaStreamTrack? track</dt>

        <dd>
          <p>&nbsp;</p>
        </dd>
      </dl>
    </section>

    <section>
      <h2>Video and Audio Tracks</h2>

      <p>The <code><a>MediaStreamTrack</a></code> object cannot be
      instantiated directly. To create an instance of
      a <code><a>MediaStreamTrack</a></code>, one of its derived track
      types may be instantiated. These derived types are defined in
      this section.</p>

      <p>Note that the camera's <q>green light</q> doesn't come on
      when a new track is created; nor does the user get prompted to
      enable the camera/microphone. Those actions only happen after
      the developer has requested that a media stream
      containing <code>"new"</code> tracks be bound to a source
      via <code><a>getUserMedia()</a></code>. Until that point tracks
      are inert.</p>

      <section>
        <h2>VideoStreamTrack interface</h2>

        <p>Video tracks may be instantiated with optional media track
        constraints. These constraints can be later modified on the
        track as needed by the application, or created after-the-fact
        if the initial constraints are unknown to the application.</p>

        <div class="note">
          <p><strong>Example: </strong> <code><a>VideoStreamTrack</a></code>
          objects are instantiated in JavaScript using the new
          operator:</p>
          <pre><b>new</b> <code>VideoStreamTrack</code>();</pre>
          or
          <pre><b>new</b> <code>VideoStreamTrack</code>( { optional: [ { <code>sourceId</code>: "20983-20o198-109283-098-09812" }, { <code>width</code>: { min: 800, max: 1200 }}, { <code>height</code>: { min: 600 }}] });</pre>
          </div>

        <dl class="idl" title="interface VideoStreamTrack : MediaStreamTrack">
          <dt>Constructor(optional MediaTrackConstraints videoConstraints)</dt>
          <dd></dd>
        </dl>
      </section>
                    
      <section>
        <h2>AudioStreamTrack</h2>
                
          <div class="note">
            <p><strong>Example: </strong><code><a>AudioStreamTrack</a></code> objects are instantiated in JavaScript using the new operator:</p>
              <pre><b>new</b> <code>AudioStreamTrack</code>();</pre>
              or
              <pre><b>new</b> <code>AudioStreamTrack</code>( { optional: [ { <code>sourceId</code>: "64815-wi3c89-1839dk-x82-392aa" }, { <code>gain</code>: 0.5 }] });</pre>
            </div>

          <dl class="idl" title="interface AudioStreamTrack : MediaStreamTrack">
            <dt>Constructor(optional MediaTrackConstraints audioConstraints)</dt>
            <dd></dd>
          </dl>
        </section>
      </section>
    </section>

    <section>
      <h2>The model:  sources, sinks, constraints, and states</h2>

      <p>Browsers provide a media pipeline from sources to sinks.  In
      a browser, sinks are the &lt;img&gt;, &lt;video&gt; and
      &lt;audio&gt; tags. Traditional sources include camera,
      microphones, streamed content, files and web resources.  The
      media produced by these sources typically does not change over
      time - these sources can be considered to be static.</p>
	
      <p>The sinks that display these sources to the user (the actual
      tags themselves) have a variety of controls for manipulating the
      source content.  For example, an &lt;img&gt; tag scales down a
      huge source image of 1600x1200 pixels to fit in a rectangle
      defined with <code>width="400"</code>
      and <code>height="300"</code>.</p>

      <p>The getUserMedia API adds dynamic sources such as microphones
      and cameras - the characteristics of these sources can change in
      response to application needs. These sources can be considered
      to be dynamic in nature. A &lt;video&gt; element that displays
      media from a dynamic source can either perform scaling or it can
      feed back information along the media pipeline and have the
      source produce content more suitable for display.</p>

      <div class="note">
        <p><strong>Note: </strong> This sort of feedback loop is
        obviously just enabling an "optimization", but it's a
        non-trivial gain. This optimization can save battery, allow
        for less network congestion, etc...</p>
      </div>

      <p>Note that <code>MediaStream</code> sinks
      (such as <code>&lt;video&gt;</code>, <code>&lt;audio&gt;</code>,
      and even <code>RTCPeerConnection</code>) will continue to have
      mechanisms to further transform the source stream beyond that
      which the <a>state</a>s, <a>capabilities</a>,
      and <a>constraints</a> described in this specification
      offer. (The sink transformation options, including
      those of <code>RTCPeerConnection</code>, are outside the scope of
      this specification.)</p>

      <p>The act of changing or applying a track constraint may affect
      the <a>state</a> of all
      tracks sharing that source and consequently all down-level sinks
      that are using that source. Many sinks may be able to take these
      changes in stride, such as the <code>&lt;video&gt;</code>
      element or <code>RTCPeerConnection</code>.  Others like the
      Recorder API may fail as a result of a source state change.</p>

      <p>The <code>RTCPeerConnection</code> is an interesting object
      because it acts simultaneously as both a
      sink <strong>and</strong> a source for over-the-network
      streams. As a sink, it has source transformational capabilities
      (e.g., lowering bit-rates, scaling-up or down resolutions,
      adjusting frame-rates), and as a source it could have its own
      states changed by a track source (though in this specification
      sources with the <code><a>remote</a></code> attribute set to
      true do not consider the current constraints applied to a
      track).  </p>

      <p>To illustrate how changes to a given source impact various
      sinks, consider the following example. This example only uses
      width and height, but the same principles apply to any of
      the <a>state</a>s exposed
      in this proposal. In the first figure a home client has obtained
      a video source from its local video camera. The source's width
      and height state are 800 pixels by 600 pixels,
      respectively. Three <code><a>MediaStream</a></code> objects on
      the home client contain tracks that use this
      same <code><a>sourceId</a></code>. The three media streams are
      connected to three different sinks:  a <code>&lt;video&gt;</code>
      element (A), another <code>&lt;video&gt;</code> element (B), and
      a peer connection (C). The peer connection is streaming the
      source video to an away client. On the away client there are two
      media streams with tracks that use the peer connection as a
      source. These two media streams are connected to
      two <code>&lt;video&gt;</code> element sinks (Y and Z).  </p>
            
      <img alt="Changing media stream source effects: before the
      requested change" src="images/change_states_before.png"/>

      <p>Note that at this moment, all of the sinks on the home client
      must apply a transformation to the original source's provided
      state dimensions. A is scaling the video up (resulting in loss
      of quality), B is scaling the video down, and C is also scaling
      the video up slightly for sending over the network. On the away
      client, sink Y is scaling the video way down, while sink Z is
      not applying any scaling.</p>

      <p>Using the constraint APIs, the
      home client's video source is changed to a higher resolution
      (1920 by 1200 pixels).</p>

      <img alt="Changing media stream source effects: after the
      requested change" src="images/change_states_after.png">

      <p>Note that the source change immediately affects all of the
      sinks on the home client, but does not impact any of the sinks (or
      sources) on the away client. With the increase in the home
      client source video's dimensions, sink A no longer has to
      perform any scaling, while sink B must scale down even further
      than before.  Sink C (the peer connection) must now scale down
      the video in order to keep the transmission constant to the away
      client.  </p>

      <p>While not shown, an equally valid states change request
      could be made of the away client video source (the peer
      connection on the away client's side).  This would not only
      impact sink Y and Z in the same manner as before, but would also
      cause re-negotiation with the peer connection on the home client
      in order to alter the transformation that it is applying to the
      home client's video source. Such a change <strong>would
      not</strong> change anything related to sink A or B or the home
      client's video source.  </p>
			
      <p>Note that this specification does not define a
      mechanism by which a change to the away client's video source
      could automatically trigger a change to the home client's
      video source. Implementations may choose to make such
      source-to-sink optimizations as long as they only do so within
      the constraints established by the application, as the next
      example demonstrates.</p>
			
      <p>It is fairly obvious that changes to a given source will
      impact sink consumers. However, in some situations changes to a
      given sink may also be cause for implementations to adjust the
      characteristics of a source's stream. This is illustrated in the
      following figures. In the first figure below, the home client's
      video source is sending a video stream sized at 1920 by 1200
      pixels. The video source is also unconstrained, such that the
      exact source dimensions are flexible as far as the application
      is concerned. Two <code><a>MediaStream</a></code> objects contain
      tracks with the same <code><a>sourceId</a></code>, and
      those <code><a>MediaStream</a></code>s are connected to two
      different <code>&lt;video&gt;</code> element sinks A and B. Sink
      A has been sized to <code>width="1920"</code>
      and <code>height="1200"</code> and is displaying the source's
      video content without any transformations. Sink B has been sized
      smaller and, as a result, is scaling the video down to fit its
      rectangle of 320 pixels across by 200 pixels down.</p>

      <img alt="Changing media stream sinks may affect sources:
      before the requested change" src="images/change_states_before2.png"/>
			
      <p>When the application changes sink A to a smaller dimension
      (from 1920 to 1024 pixels wide and from 1200 to 768 pixels
      tall), the browser's media pipeline may recognize that none of
      its sinks require the higher source resolution, and needless
      work is being done both on the part of the source and on sink
      A. In such a case and without any other constraints forcing the
      source to continue producing the higher resolution video, the
      media pipeline MAY change the source resolution:</p>
				
      <img alt="Changing media stream sinks may affect sources:
      after the requested change" src="images/change_states_after2.png"/>
            
      <p>In the above figure, the home client's video source
      resolution was changed to the greater of that from sinkA and
      from sinkB in order to optimize playback. While not shown above,
      the same behavior could apply to peer connections and other
      sinks.</p>

      <p>It is possible that constraints can be applied to a track
      which a source is unable to satisfy. When this happens, the user
      agent is required to fire an "overconstrained" event to the
      track informing it of this condition, and the track becomes
      muted. There is no mandatory side-effect on the source itself as
      a result of this condition.</p>
 
      <p>When multiple tracks share the same source (as illustrated in
      the previous figures), it is also possible that two (or more)
      tracks can apply contradictory constraints on the source. Since
      there is only a single thread of control, it is always possible
      for the browser to determine which track created the
      overconstrained condition.  In this situation, the user agent
      MUST send the "overconstrained" event only to the track that
      created the condition and MUST not apply any of the constraints
      newly requested for that track.  Here is an example of this
      behavior.</p>

 
      <p>In this example, two media streams each have a video track
      that share the same source. The first track has a mandatory
      constraint forcing on the source's fill light. That track is
      connected to sink N. Sink N has a width and height of 800 by 600
      pixels and is scaling down the source's resolution of 1024 by
      768 to fit. The other track initially has no constraints
      applied; it is connected to sink P. Sink P has a width and
      height equal to that of the source.</p>

      <p><img alt="Overconstrained"
      src="images/overconstrained_before.png"></p>

      <p>Now, the second track adds a mandatory constraint that the
      fill light should be forced off. At this point, both mandatory
      constraints cannot be satisfied by the source (the fill light
      cannot be simultaneously on and off at the same time). The
      second track is transitioned into the muted state and receives
      an "overconstrained" event. At the same time, the source notes
      that its remaining active sink only requires a resolution of 800
      by 600 and so it adjusts its resolution down to match (this is
      an optional optimization that the user agent is allowed to make
      given the situation).</p>
 
      <p>At this point, it is the responsibility of the application to
      fix the problem that led to the overconstrained situation (by
      either removing the fill light mandatory constraint on the
      second track, or by changing/removing the fill light mandatory
      constraint on the first track).</p>

      <p><img alt="Overconstrained result"
      src="images/overconstrained_after.png"></p>

    </section>

    <section>
      <h2>Source states</h2>

      <p>There is a variable associated with each capability that
      represents the state of the source with respect to that
      capability, the actual setting in use by the source.  In the same
      way that the current set of constraints can be returned on a
      track using the <code><a>constraints()</a></code> method,
      the <code><a>states()</a></code> method on a track returns the
      values of the state variables associated with all capabilities,
      as the <code><a>MediaSourceStates</a></code> object.  Only
      states appropriate to the <code><a>sourceType</a></code> are
      returned.</p>

      <div class="note">
          <p><strong>Note: </strong>The following specific list(s) of
          states DOES NOT REFLECT CONSENSUS.  Many states beyond these
          have been proposed, and the ones listed do not have
          universal support.  The ones below are included **** ONLY
          **** to provide a starting point so we can see concrete
          examples of what real states might look like.  The
          particular set below was chosen to match
          the <a href="#sec-constraints">**also temporary** set of
          constraints</a>.</p>
      </div>
 
      <dl class="idl" title="dictionary MediaSourceStates">
        <dt>SourceTypeEnum sourceType</dt>
        <dd>The type information associated with the currently
        attached source.  Returned for all types of sources (video,
        audio, etc.).</dd>

        <dt>DOMString sourceId</dt>
        <dd>The application-unique identifier for this source. The
        same identifier must be valid between sessions of this
        application, but must also be different for other
        applications. Some sort of GUID is recommended for the
        identifier.  Returned for all types of sources (video, audio, etc.).
        </dd>

        <dt>unsigned long? width</dt>
        <dd>The width (in pixels) of the source of the video flowing
        through the track.  Returned for video sources.</dd>

        <dt>unsigned long? height</dt>
        <dd>The height (in pixels) of the source of the video flowing
        through the track.  Returned for video sources.</dd>

        <dt>float? frameRate</dt>
        <dd>The current frames per second rate of video provided by
        this source.  If the source does not provide a frameRate (or
        the frameRate cannot be determined from the source stream),
        then this attribute MUST be the user agent's vsync display
        rate.  Returned for video sources.</dd>

        <dt>float? aspectRatio</dt>
        <dd>The current aspect ratio for the source.  Aspect ratio is
        width in pixels divided by height in pixels, rounded to the
        tenth decimal place.  Returned for video sources.</dd>

        <dt>VideoFacingModeEnum? facingMode</dt>
        <dd>From the user's perspective, this value describes whether
        this camera is pointed toward the user ("user") or away from
        the user ("environment").  Returned for video sources.</dd>

        <dt>unsigned long? volume</dt>
        <dd>The current audio track's volume (as a percentage).  A
        volume of 0 is silence, while a volume of 100 is the maximum
        supported volume.  Returned for audio sources.</dd>
      </dl>

    </section>

    <section>
      <h2>Source capabilities</h2>

      <p>Each constraint that is supported by an implementation MUST
      have an associated capability that will be returned in the
      result of a call to the <code><a>capabilities()</a></code>
      method.</p>

      <p>Capabilities are provided as either a min/max range or a
      list of enumerated values. Min/max capabilities are
      always provided for <a>constraints</a> that are not enumerated
      types. Listed capabilities are always provided for
      <a>constraints</a>
      corresponding to enumerated types.</p>

 
      <dl class="idl" title="dictionary CapabilityRange">
        <dt>any max</dt>
        <dd>The maximum value of this capability. 
          <p>The type of this value is specific to the capability.</p>
          <p>If the related capability is not supported by the source,
          then this field will not be provided by the user agent (it
          will be <code>undefined</code>).</p>
        </dd>

        <dt>any min</dt>
        <dd>The minimum value of this capability. 
          <p>The type of this value is specific to the capability.</p>
          <p>If the related capability is not supported by the source,
          then this field will not be provided by the user agent (it
          will be <code>undefined</code>).</p>
        </dd>

        <dt>boolean supported</dt>
        <dd>Returns the value <code>true</code> if the capability is
        supported, false otherwise.</dd>
      </dl>

      <section>
        <h2>CapabilityList array</h2>
      
        <dl class="idl" title="typedef sequence&lt;DOMString&gt;
        CapabilityList"></dl>
	
        <p>Capability Lists are just an array of
        supported <code>DOMString</code> values from the possible
        superset of values described by each
        <a>state</a>'s enumerated type.</p>
	
      </section>
 

      <div class="note">
          <p><strong>Note: </strong>The following specific list(s) of
          capabilities DOES NOT REFLECT CONSENSUS.  Many capabilities
          beyond these have been proposed, and the ones listed do not
          have universal support.  The ones below are included ****
          ONLY **** to provide a starting point so we can see concrete
          examples of what real capabilities might look like.  The
          particular sets below were chosen to match
          the <a href="#sec-constraints">**also temporary** set of
          constraints</a>.</p>
      </div>

      <dl class="idl" title="dictionary AllVideoCapabilities">
        <dt>CapabilityList? sourceType</dt>
        <dd>The available sourceType options
        (<code><a>SourceTypeEnum</a></code>) on the current source.</dd>

        <dt>CapabilityList? sourceId</dt>
        <dd>The available source identifiers of the current
        source -- this will always return a list with a single
        identifier (that of the current source).</dd>

        <dt>CapabilityRange? width</dt>
        <dd>The range should span the video source's pre-set width
        values with min being the smallest width, and max the largest
        width. The type of the min/max values are unsigned long.</dd>

        <dt>CapabilityRange? height</dt>
        <dd>The range should span the video source's pre-set height
        values with min being the smallest height, and max the largest
        height. The type of the min/max values are unsigned long.</dd>

        <dt>CapabilityRange? frameRate</dt> <dd>The supported range of frame
        rates on the source. The type of the min/max values are float.</dd>

        <dt>CapabilityRange? aspectRatio</dt> <dd>The supported range
        of aspect ratio defined as a floating point number rounded to
        10 decimal places on the source and representing the width in
        pixels divided by the height in pixels. The type of the
        min/max values are float.</dd>

        <dt>CapabilityList? facingMode</dt>
	
        <dd>The available video facing options
        (<code><a>VideoFacingModeEnum</a></code>) on the source.</dd>
	
      </dl>


      <dl class="idl" title="dictionary AllAudioCapabilities">
        <dt>CapabilityRange? volume</dt>
        <dd>The supported range of output volume percentages on the
        source. The type of the min/max values are unsigned long.</dd>
      </dl>
    </section>

    <section>
      <h2>URL</h2>

      <dl class="idl" title="partial interface URL">
        <dt>static DOMString createObjectURL (MediaStream stream)</dt>

        <dd>
          <p>Mints a <a href="#blob-url">Blob URL</a> to refer to the given
          <code><a>MediaStream</a></code>.</p>

          <p>When the <dfn id=
          "dom-url-createobjecturl"><code>createObjectURL()</code></dfn> method
          is called with a <code><a>MediaStream</a></code> argument, the user
          agent MUST return a unique <a href="#blob-url">Blob URL</a> for the
          given <code><a>MediaStream</a></code>. [[!FILE-API]]</p>

          <p>For audio and video streams, the data exposed on that stream MUST
          be in a format supported by the user agent for use in
          <code>audio</code> and <code>video</code> elements.</p>

          <p class="bookkeeping">A <dfn id="blob-url">Blob URL</dfn> is the
          same as what the File API specification calls a Blob URI, except that
          anything in the definition of that feature that refers to
          <code>File</code> and <code>Blob</code> objects is hereby extended to
          also apply to <code><a>MediaStream</a></code> objects.</p>
        </dd>
      </dl>
    </section>

    <section>
      <h2>MediaStreams as Media Elements</h2>

      <p>A <code>MediaStream</code> may be assigned to media elements
      as defined in <a href=
      "http://www.w3.org/TR/html5/embedded-content-0.html#media-elements">HTML5</a>
      [[!HTML5]] A <code>MediaStream</code> is not preloadable or
      seekable and represents a simple, potentially infinite, linear
      media timeline. The timeline starts at 0 and increments linearly
      in real time as long as the <code>MediaStream</code> is
      playing. The timeline does not increment when the
      <code>MediaStream</code> is paused.</p>
     
     <section>
      <h3>Direct Assignment to Media Elements</h3>
      
      <p>There are two methods by which a MediaStream may be assigned
      to a media element.  First, <code><a>createObjectURL</a></code>
      can be used to obtain a URL for the <code>MediaStream</code>.
      That URL can then be used to set the <code>src</code> attribute
      of the media element itself, or of one of its &lt;source&gt;
      children.  Secondly, UAs that support this specification MUST
      support the following partial interface, which allows a
      MediaStream to be assigned directly to a media element.  </p>
      	
      <dl class="idl" title="partial interface HTMLMediaElement">

	<dt>attribute MediaStream? srcObject </dt>
	
	<dd><p>Holds the MediaStream that provides media for this
	  element. This attribute overrides both the <code>src</code>
	  attribute and any &lt;source&gt; elements. Specifically, if
	  <code>srcObject</code> is specified, the UA MUST use it as
	  the source of media, even if the <code>src</code> attribute
	  is also set or &lt;source&gt; children are present.  If the
	  value of <code>srcObject</code> is replaced or set to null
	  the UA MUST re-run the <a href=
	  "http://www.w3.org/TR/html5/embedded-content-0.html#media-element-load-algorithm">
	  media element load algorithm</a>
        	
        	</p></dd>
		
      </dl> 	

 <p class="issue"> We may want to allow direct assignment of other types as well </p>
 </section> 
 <section>
 	<h3>Loading and Playing a MediaStream in a Media Element</h3>
      
      <p>The UA runs the <a href=
        "http://www.w3.org/TR/html5/embedded-content-0.html#media-element-load-algorithm">
        media element load algorithm</a> to obtain media for the media
        element to display.  As defined in the [[HTML5]]
        specification, this algorithm has two basic phases: <a
         href="http://www.w3.org/TR/html5/embedded-content-0.html#concept-media-load-algorithm">
        resource selection algorithm</a> chooses the resource to play
        and resolves its URI. Then the <a
         href="http://www.w3.org/TR/html5/embedded-content-0.html#concept-media-load-resource">
        resource fetch phase</a> loads the resource. Both these phases
        are potentially simplified when using a MediaStream.  First of
        all, in the case of direct assignment, <code>srcObject</code>
        takes priority over other means of specifying the resource.
        Futhermore, it provides the object itself rather than a URI.
        In this case, there is no need to run the resource selection
        algorithm.  Secondly, when the UA reaches the resource fetch
        algorithm with a MediaStream (whether specified by URI or
        direct assignment), the MediaStream is a local object so
        there's nothing to fetch.  Therefore, the following
        modifications/restrictions to the <a href=
        "http://www.w3.org/TR/html5/embedded-content-0.html#media-element-load-algorithm">
        media element load algorithm</a> apply: </p>

      <ul>

        <li>
          <p>Whenever the user agent runs the <a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#media-element-load-algorithm">
          media element load algorithm</a>, if <code>srcObject</code> is
          specified, the UA must immediately go to the <a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#concept-media-load-resource">
          resource fetch phase</a> of the algorithm. (Note that in this
          case, the UA will have the MediaStream object, and not an
          absolute URI, as it would if the MediaStream had been
          specified by <code>src</code> or &lt;source&gt;.  However the
          load operation on a MediaStream is trivial in all cases, as
          indicated in the next item.)</p>
        </li>

        <li>
          <p>Whenever the user agent runs the <a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#media-element-load-algorithm">
          media element load algorithm</a>, reaches the <a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#concept-media-load-resource">
          resource fetch phase</a> of this algorithm, and determines
          that the media resource in question is a MediaStream, it MUST
          immediately abort the <a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#concept-media-load-algorithm">
          resource selection algorithm</a>, setting the <a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-readystate">
          <code>media.readyState</code></a> to HAVE_NOTHING if media is
          not yet available and to HAVE_ENOUGH_DATA once it is.</p>
        </li>

        <li>
          <p>For each <code><a>MediaStreamTrack</a></code> in the
          <code><a>MediaStream</a></code>, including those that are added after
          the UA enters the <a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#media-element-load-algorithm">
          media element load algorithm</a>, the UA MUST create a
          corresponding <code><a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#audiotrack">
          AudioTrack</a></code> or <code><a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#videotrack">
          VideoTrack</a></code> as defined in [[!HTML5]]. Since the order in
          the <code><a>MediaStream</a></code>'s <a href=
          "#track-set">track set</a> is undefined, no requirements are put how
          the <code><a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#audiotracklist">
          AudioTrackList</a></code> and <code><a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#videotracklist">
          VideoTrackList</a></code> are ordered.</p>

          <p>The properties of the <code>AudioTrack</code> and
          <code>VideoTrack</code> objects MUST be initialized as follows.
          Let</p>

          <ul>
            <li>
              <p><code>AudioTrack.id</code> and <code>VideoTrack.id</code>
              have the value of the corresponding <code><a href=
              "#dom-mediastreamtrack-id">MediaStreamTrack.id</a></code>
              attribute</p>
            </li>

            <li>
              <p><code>AudioTrack.kind</code> and
              <code>VideoTrack.kind</code> be <code>"main"</code>
              </p>
            </li>

            <li>
              <p><code>AudioTrack.label</code> and
              <code>VideoTrack.label</code> have the value of the corresponding
              <code><a href=
              "#dom-mediastreamtrack-label">MediaStreamTrack.label</a></code>
              attribute</p>
            </li>

            <li>
              <p><code>AudioTrack.language</code> and
              <code>VideoTrack.language</code> be the empty string</p>
            </li>

            <li>
              <p><code>AudioTrack.enabled</code> be <code>true</code></p>
            </li>
          </ul>

          <p>Set the <code><a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#dom-videotracklist-selectedindex">
          VideoTrackList.selectedIndex</a></code> to the index of the first
          <code><a>VideoTack</a></code>, in the <code>VideoTrackList</code>,
          that corresponds to a <code><a>MediaStreamTrack</a></code> that is
          not <a href="#track-muted">muted</a> or <a href="#track-enabled">disabled</a>. If
          no such <code>VideoTack</code> exists, set the
          <code>selectedIndex</code> attribute to 0.</p>

          <p>(Note that since the
          MediaStream is potentially endless, the UA does not exit the
          <a href=
          "http://www.w3.org/TR/html5/embedded-content-0.html#media-element-load-algorithm">
          media element load algorithm</a> until the MediaStream moves
          from the active to the <a href="#stream-inactive">inactive</a> state.)</p>
        </li>

        <li>
          <p>If a <code><a>MediaStreamTrack</a></code> is removed from a
          <code><a>MediaStream</a></code>, played by a media element, the
          corresponding <code>AudioTrack</code> or <code>VideoTrack</code> MUST
          be removed as well.</p>
        </li>

        <li>
          <p>The UA MUST NOT buffer data from a MediaStream. When
          playing, the UA MUST always play the current data from the
          stream.</p>
        </li>

        <li>
          <p>When the MediaStream is moves from the active to the
          <a href="#stream-inactive">inactive</a> state, the UA MUST raise an <a
          href="http://www.w3.org/TR/html5/embedded-content-0.html#event-media-ended">ended</a>
          event on the media element and set its <a
          href="http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-ended">ended</a>
          attribute to <code>true</code>. Note that once <a
          href="http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-ended">ended</a>
          equals <code>true</code> the media element will not play media
          even if new Tracks are added to the MediaStream (causing it to
          return to the active state) until the JavaScript restarts the
          element, e.g., by calling <a
          href="http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-play">play()</a>.</p>
        </li>
      </ul>
      
      <p class="issue">If a MediaStream is inactive and the media
      	element is ended, and the element's <code>autoplay</code>
      	attribute is set to true, should it start playing
      	automatically if new Tracks are added to the MediaStream?</p>
      
</section>
<section>
      
      <h3>Media Element Attributes when Playing a MediaStream</h3>

      <p>The nature of the <code>MediaStream</code> places certain restrictions on the
      behavior and attribute values of the associated media element and on the
      operations that can be performed on it, as shown below:</p>
      <table      class="simple"><caption>
      Legal values for the properties of a media element bound to a MediaStream</caption>
        <thead>
          <tr>
            <th scope="col">Attribute Name</th>

            <th scope="col">Attribute Type</th>

            <th scope="col">Valid Values When Using a MediaStream</th>

            <th scope="col">Additional considerations</th>
          </tr>
        </thead>

        <tbody>
          <tr>
            <td>
              <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-src"
              class="externalDFN"><code>src</code></a>
            </td>

            <td><code>DOMString</code></td>

            <td>a local URI referencing a MediaStream</td>

            <td>The markup author can use this attribute to specify
            	the source of the media.  <code>createObjectURI</code>
            	can be used to generate a URI referring to a
            	MediaStream which can be used as the value of this
            	attribute.  In such a case, revocation of the URI does
            	not count as a change to this field and does not
            	trigger the media element load algorithm.</td> </tr>

          <tr>
            <td>
              <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-currentsrc"
              class="externalDFN"><code>currentSrc</code></a>
            </td>

            <td><code>DOMString</code></td>

            <td>a local URI referencing a MediaStream or the empty string</td>

            <td>The UA automatically sets the value of this attribute.
              When <code>srcObject</code> is specified the UA MUST
            	set it to the empty string. </td>
		
          </tr>

          <tr>
            <td>
              <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#attr-media-preload"
              class="externalDFN"><code>preload</code></a>
            </td>

            <td><code>DOMString</code></td>

            <td><code>none</code></td>

            <td>A MediaStream cannot be preloaded.</td>
          </tr>

          <tr>
            <td>
              <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-buffered"
              class="externalDFN"><code>buffered</code></a>
            </td>

            <td>
              <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#timeranges"
              class="externalDFN"><code>TimeRanges</code></a>
            </td>

            <td><code>buffered.length</code> MUST return <code>0</code>.</td>

            <td>A MediaStream cannot be preloaded. Therefore, the amount
            buffered is always an empty TimeRange.</td>
          </tr>
                        <tr>
            <td>
              <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-networkstate"
              class="externalDFN"><code>networkState</code></a>
            </td>

            <td><code>unsigned short</code></td>

            <td>NETWORK_IDLE	</td>

            <td>The media element does not fetch the MediaStream so there is no network traffic. </td>
          </tr>
              <tr>
            <td>
              <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-readystate"
              class="externalDFN"><code>readyState</code></a>
            </td>

            <td><code>unsigned short</code></td>

            <td>HAVE_NOTHING, HAVE_ENOUGH_DATA</td>

            <td>A <code><a>MediaStream</a></code> may be created before there
            is any data available, for example when a stream is received from a
            remote peer. The value of the <code>readyState</code> of
            the media element MUST
            be HAVE_NOTHING before the first media arrives
            and HAVE_ENOUGH_DATA once the first media has arrived.</td>
          </tr>
          <tr>
            <td>
              <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-currenttime"
              class="externalDFN"><code>currentTime</code></a>
            </td>

            <td><code>double</code></td>

            <td>Any positive integer. The initial value is 0 and the values
            increments linearly in real time whenever the stream is
            playing.</td>

            <td>The value is the current stream position, in seconds. On any
            attempt to set this attribute, the user agent must throw an
            <code>InvalidStateError</code> exception.</td>
          </tr>

          <tr>
            <td>
              <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-duration"
              class="externalDFN"><code>duration</code></a>
            </td>

            <td><code>unrestricted double</code></td>

            <td>Infinity</td>

            <td>
              A MediaStream does not have a pre-defined duration.
            </td>
          </tr>

          <tr>
            <td>
              <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-seeking"
              class="externalDFN"><code>seeking</code></a>
            </td>

            <td><code>boolean</code></td>

            <td>false</td>

            <td>A MediaStream is not seekable. Therefore, this attribute
            MUST always have the value
            <code>false</code>.</td>
          </tr>

          <tr>
            <td>
              <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-defaultplaybackrate"
              class="externalDFN"><code>defaultPlaybackRate</code></a>
            </td>

            <td><code>double</code></td>

            <td>1.0</td>

            <td>A MediaStream is not seekable. Therefore, this attribute
            MUST always have the value
            <code>1.0</code> and any attempt to alter it MUST fail.</td>
          </tr>

          <tr>
            <td>
              <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-playbackrate"
              class="externalDFN"><code>playbackRate</code></a>
            </td>

            <td><code>double</code></td>

            <td>1.0</td>

            <td>A MediaStream is not seekable. Therefore, this attribute
            MUST always have the value
            <code>1.0</code> and any attempt to alter it MUST fail.</td>
          </tr>

          <tr>
            <td>
              <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-played"
              class="externalDFN"><code>played</code></a>
            </td>

            <td>
              <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#timeranges"
              class="externalDFN"><code>TimeRanges</code></a>
            </td>

            <td>
              <code>played.length</code> MUST return <code>1</code>.<br>
              <code>played.start(0)</code> MUST return <code>0</code>.<br>
              <code>played.end(0)</code> MUST return the last known <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-currenttime"
              class="externalDFN"><code>currentTime</code></a>.
            </td>

            <td>A MediaStream's timeline always consists of a single range,
            starting at 0 and extending up to the currentTime.</td>
          </tr>

          <tr>
            <td>
              <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-seekable"
              class="externalDFN"><code>seekable</code></a>
            </td>

            <td>
              <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#timeranges"
              class="externalDFN"><code>TimeRanges</code></a>
            </td>

            <td>
              <code>seekable.length</code> MUST return <code>0</code>.<br>
              <code>seekable.start()</code> MUST return <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-currenttime"
              class="externalDFN"><code>currentTime</code></a>.<br>
              <code>seekable.end()</code> MUST return <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-currenttime"
              class="externalDFN"><code>currentTime</code></a>.
            </td>

            <td>A MediaStream is not seekable.</td>
          </tr>

          <tr>
            <td>
              <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-startdate"
              class="externalDFN"><code>startDate</code></a>
            </td>

            <td><code>Date</code></td>

            <td>Not-a-Number (NaN)</td>

            <td>A MediaStream does not specify a timeline offset.</td>
          </tr>

          <tr>
            <td>
              <a href=
              "http://www.w3.org/TR/html5/embedded-content-0.html#dom-media-loop"
              class="externalDFN"><code>loop</code></a>
            </td>

            <td><code>boolean</code></td>

            <td>true, false</td>

            <td>Setting the <code>loop</code> attribute has no effect since a
            <code><a>MediaStream</a></code> has no defined end and therefore
            cannot be looped.</td>
          </tr>
          

        </tbody>
      </table>
      	</section>
    </section>

    <section class="informative">
      <h2>Event summary</h2>

      <p>The following event fires on <code>
          <a>MediaStream</a>
        </code> objects:</p>

      <table>
        <tr>
          <th>Event name</th>

          <th>Interface</th>

          <th>Fired when...</th>
        </tr>

        <tbody>
          <tr>
            <td>
              <dfn id="event-mediastream-active">
                <code>active</code>
              </dfn>
            </td>

            <td>
              <code>Event</code>
            </td>

            <td>The <code><a>MediaStream</a></code> became active (see <a href=
            "#stream-inactive">inactive</a>).</td>
          </tr>

          <tr>
            <td>
              <dfn id="event-mediastream-inactive">
                <code>inactive</code>
              </dfn>
            </td>

            <td>
              <code>Event</code>
            </td>

            <td>The <code><a>MediaStream</a></code> became <a href=
            "#stream-inactive">inactive</a>.</td>
          </tr>

          <tr>
            <td>
              <dfn id="event-mediastream-addtrack"><code>addtrack</code></dfn>
            </td>

            <td>
              <code>
                <a>MediaStreamTrackEvent</a>
              </code>
            </td>

            <td>A new <code> <a>MediaStreamTrack</a> </code> has been added to
            this stream. Note that this event is not fired when the script
            directly modifies the tracks of a <code><a>MediaStream</a></code>.
          </td>
          </tr>

          <tr>
            <td>
              <dfn id="event-mediastream-removetrack"><code>removetrack</code>
              </dfn>
            </td>

            <td>
              <code>
                <a>MediaStreamTrackEvent</a>
              </code>
            </td>

            <td>A <code><a>MediaStreamTrack</a></code> has been removed from
            this stream. Note that this event is not fired when the script
            directly modifies the tracks of a <code><a>MediaStream</a></code>.
            </td>
          </tr>
        </tbody>
      </table>

      <p>The following event fires on <code>
          <a>MediaStreamTrack</a>
        </code> objects:</p>

      <table>
        <tr>
          <th>Event name</th>

          <th>Interface</th>

          <th>Fired when...</th>
        </tr>

        <tbody>
          <tr>
            <td>
              <dfn id="event-mediastreamtrack-started">
                <code>started</code>
              </dfn>
            </td>

            <td>
              <code>Event</code>
            </td>

            <td>The <code><a>MediaStreamTrack</a></code>
              object has just transitioned from the
              "new" <code><a>readyState</a></code> to another state.
              This event fires before any other corresponding events
              such as "ended" or "statechanged".</td>
          </tr>

          <tr>
            <td>
              <dfn id="event-mediastreamtrack-mute">
                <code>mute</code>
              </dfn>
            </td>

            <td>
              <code>Event</code>
            </td>

            <td>The <code>
                <a>MediaStreamTrack</a>
              </code> object's source is temporarily unable to provide
            data.</td>
          </tr>

          <tr>
            <td>
              <dfn id="event-mediastreamtrack-unmute">
                <code>unmute</code>
              </dfn>
            </td>

            <td>
              <code>Event</code>
            </td>

            <td>The <code>
                <a>MediaStreamTrack</a>
              </code> object's source is live again after having been
            temporarily unable to provide data.</td>
          </tr>

          <tr>
            <td>
              <dfn id="event-mediastreamtrack-overconstrained">
                <code>overconstrained</code>
              </dfn>
            </td>

            <td>
              <code>Event</code>
            </td>

            <td>
              <p>This event fires asynchronously for each affected
              track (when multiple tracks share the same source) after
              the user agent has evaluated the current constraints
              against a given <code><a>sourceId</a></code> and is not
              able to configure the source within the limitations
              established by the union of imposed constraints.</p>

              <p>Due to being over-constrained, the user
              agent must mute each affected track.</p>
              <p>The affected track(s) will remain un-usable (in
              the <code>"muted"</code> <a>readyState</a>) until the
              application adjusts the constraints to accommodate the
              source's capabilities.</p>
              <p>The "overconstrained" event is a simple event of
              type <code>Event</code>; it carries no information about
              which constraints caused the source to be
              over-constrained (the application has all the necessary
              APIs to figure it out).</p>
            </td>
          </tr>


          <tr>
            <td>
              <dfn id="event-mediastreamtrack-ended">
                <code>ended</code>
              </dfn>
            </td>

            <td>
              <code>Event</code>
            </td>

            <td>The <code>
                <a>MediaStreamTrack</a>
              </code> object's source will no longer provide any data, either
            because the user revoked the permissions, or because the source
            device has been ejected, or because the remote peer stopped
            sending data, or because the <code>
                <a href="#widl-MediaStreamTrack-stop-void">stop()</a>
              </code> method was invoked.</td>
          </tr>
        </tbody>
      </table>
    </section>
  </section>

  <section id="local-content">
    <h2>Obtaining local multimedia content</h2>

    <section>
      <h2>NavigatorUserMedia</h2>

      <dl class="idl" title="[NoInterfaceObject] interface NavigatorUserMedia">
        <dt>void getUserMedia(MediaStreamConstraints? constraints,
        NavigatorUserMediaSuccessCallback successCallback,
        NavigatorUserMediaErrorCallback errorCallback)</dt>

        <dd>
          <p>Prompts the user for permission to use their Web cam or other
          video or audio input.</p>

          <p class="issue">The syntax for getUserMedia() is still
          under discussion.  Some questions are: whether it creates
          media streams or just initializes ones already created;
          whether it creates streams synchronously (immediate return
          of MediaStream with callback later when user grants
          permission) or asynchronously (MediaStream available only
          upon callback).</p>

          <p>The <var>constraints</var> argument is an object of type
          <code><a>MediaStreamConstraints</a></code>.</p>

          <p>The <var>successCallback</var> will be invoked with a suitable
          <code><a>MediaStream</a></code> object as its argument if the
          user accepts valid tracks as described below.</p>

          <p>The <var>errorCallback</var> will be invoked if there is
          a failure in finding valid tracks or if the user denies permission,
          both as described below.</p>

          <p>When the <dfn id=
          "dom-navigator-getusermedia"><code>getUserMedia()</code></dfn> method
          is called, the user agent MUST run the following steps:</p>

          <ol>
            <li>
              <p>Let <var>constraints</var> be the method's first argument.</p>
            </li>

            <li>
              <p>Let <var>successCallback</var> be the callback indicated by
              the method's second argument.</p>
            </li>

            <li>
              <p>Let <var>errorCallback</var> be the callback indicated by the
              method's third argument.</p>
            </li>

            <li>
              <p>Let <var>requestedMediaTypes</var> be the set of media types
              in <var>constraints</var> with either a dictionary value or a
              value of "true".</p>
            </li>

            <li>
              <p>If <var>requestedMediaTypes</var> is the empty set, let
              <var>error</var> be a new
              <code><a>NavigatorUserMediaError</a></code> object whose
              <code><a>name</a></code> attribute has the value
              <code>NotSupportedError</code> and jump to the step labeled
              <em>Error Task</em> below.</p>
            </li>

            <li>
              <p>Let <var>finalSet</var> be an (initially) empty set.</p>
            </li>

            <li>
              <p>If <var>successCallback</var> is null, abort these steps.</p>
            </li><!-- we could throw an exception instead (that's
   why the method doesn't return until later: so that we can add an
   exception here, or for /options/ below, without changing the
   algorithm) -->
            <!--
            <li>
              <p>For each member of the <code><a>MediaStreamOptions</a></code>
              dictionary create a local representation and set it to false.</p>
            </li>

            <li>
              <p>For each property in <var>options</var> that is present and
              set to true, let the corresponding local representation be
              true.</p>
            </li>

            <li>
              <p>If none of the local representations of the
              <code><a>MediaStreamOptions</a></code> dictionary members is set
              to true, then throw a <code>NOT_SUPPORTED_ERR</code> exception
              and abort these steps.</p>
            </li>
-->

            <li>
              <p>For each media type <var>T</var> in
              <var>requestedMediaTypes</var>,</p>

              <ol>
                <li>
                  <p>Let <var>candidateSet</var> be all possible tracks of
                  media type <var>T</var> that the browser could return.</p>
                </li>

                <li>If the value of the <var>T</var> entry of
                <var>constraints</var> is "true", jump to the step labeled
                <em>final</em> below. Otherwise, continue.</li>

                <li>
                  <p>For each constraint key-value pair in the "mandatory"
                  dictionary,</p>

                  <ol>
                    <li>
                      <p>If the constraint is not supported by the browser,
                      jump to the step labeled <em>Constraint Failure</em>
                      below.</p>
                    </li>

                    <li>
                      <p>Remove from the <var>candidateSet</var> any track that
                      cannot satisfy the value given for the constraint.</p>
                    </li>

                    <li>
                      <p>If the <var>candidateSet</var> no longer contains at
                      least one track, jump to the step labeled
                      <em>Constraint Failure</em> below. Otherwise, continue
                      with the next mandatory constraint.</p>
                    </li>
                  </ol>
                </li>

                <li>
                  <p>Let the <var>secondPassSet</var> be the current contents
                  of the <var>candidateSet</var>.</p>
                </li>

                <li>
                  <p>For each constraint key-value pair in the "optional"
                  sequence of the <var>constraints</var> that are for the
                  current media type, in order,</p>

                  <ol>
                    <li>
                      <p>If the constraint is not supported by the browser,
                      skip it and continue with the next constraint.</p>
                    </li>

                    <li>
                      <p>Remove from the <var>secondPassSet</var> any tracks
                      that cannot satisfy the value given for the
                      constraint.</p>
                    </li>

                    <li>
                      <p>If the <var>secondPassSet</var> is now empty, let the
                      <var>secondPassSet</var> be the current contents of the
                      <var>candidateSet</var>. Otherwise, let the
                      <var>candidateSet</var> be the current contents of the
                      <var>secondPassSet</var>.</p>
                    </li>
                  </ol>
                </li>

                <li>
                  <p><em>Final:</em> Add the tracks in the
                  <var>candidateSet</var> to the <var>finalSet</var>.</p>
                </li>
              </ol>
            </li>

            <li>
              <p>Return, and run the remaining steps asynchronously.</p>
            </li>

            <li>
              <p>Optionally, e.g., based on a previously-established user
              preference, for security reasons, or due to platform limitations,
              jump to the step labeled <em>Permission Failure</em> below.</p>
            </li>

            <li>
              <p>Prompt the user in a user agent specific manner for permission
              to provide the entry script's origin with a
              <code><a>MediaStream</a></code> object representing a media
              stream.</p>

              <p>The provided media MUST include precisely one track of each
              media type in requestedMediaTypes from the <var>finalSet</var>.
              The decision of which tracks to choose from the
              <var>finalSet</var> is completely up to the user agent and may be
              determined by asking the user. Unless and until a new set of
              constraints is provided, the user agent MAY change its choice of
              track at any point, provided that 1) the new choice does not
              violate given user permissions, and 2) it notifies the
              application code by raising an event. It may wish to do this, for
              example, if the user interface or network congestion changes. Note
              that no such change will have an effect on the presence or absence
              of each type of track, merely the contents.</p>

              <p class="issue">Define the event that should be raised when the
              user agent changes its choice of track.</p>

              <p>User agents are encouraged to default to using the user's
              primary or system default camera and/or microphone (when
              possible) to generate the media stream. User agents MAY allow
              users to use any media source, including pre-recorded media
              files.</p>

              <p>If the user grants permission to use local recording devices,
              user agents are encouraged to include a prominent indicator that
              the devices are "hot" (i.e. an "on-air" or "recording"
              indicator).</p>

              <p>If the user denies permission, jump to the step labeled
              <em>Constraint Failure</em> below. If the user never responds, this
              algorithm stalls on this step.</p>
            </li>

            <li>
              <p>Let <var>stream</var> be the
              <code><a>MediaStream</a></code> object for which the user
              granted permission.</p>
            </li>

            <li>
              <p>Queue a task to invoke <var>successCallback</var> with
              <var>stream</var> as its argument.</p>
            </li>

            <li>
              <p>Abort these steps.</p>
            </li>

            <li>
              <p><em>Permission Failure</em>: Let <var>error</var> be a new
              <code><a>NavigatorUserMediaError</a></code> object whose
              <code><a>name</a></code> attribute has the value
              <code>PermissionDeniedError</code> and jump to the step
              labeled <em>Error Task</em> below.</p>
            </li>

            <li>
              <p><em>Constraint Failure</em>: Let <var>error</var> be a new
              <code><a>NavigatorUserMediaError</a></code> object whose
              <code><a>name</a></code> attribute has the value
              <code>ConstraintNotSatisfiedError</code> and whose
              <code><a href="#widl-NavigatorUserMediaError-constraintName"
              >constraintName</a></code> attribute is set to the name of the
              constraint that caused the error.</p>
            </li>

            <li>
              <p><em>Error Task:</em> Queue a task to invoke
              <var>errorCallback</var> with <var>error</var> as its argument.
              </p>
            </li>

            <li style="list-style: none; display: inline">
              <p>The task source for these <span title=
              "concept-task">tasks</span> is the user interaction task
              source.</p>
            </li>
          </ul>
        </dd>
      </dl>

      <div class="idl" title="Navigator implements NavigatorUserMedia"></div>
    </section>

    <section>
      <h2>MediaStreamConstraints</h2>

      <dl class="idl" title="dictionary MediaStreamConstraints">
        <!--        <dt>boolean audio</dt>

        <dd>Set to true if an audio track is requested, default is false</dd>

        <dt>boolean video</dt>

        <dd>Set to true if a video track is requested, default is false</dd>
-->

        <dt>(boolean or MediaTrackConstraints) video = false</dt>

        <dd>
          <p class="issue">Provide definition of video constraints here.</p>
        </dd>

        <dt>(boolean or MediaTrackConstraints) audio = false</dt>

        <dd>
          <p class="issue">Provide definition of audio constraints here.</p>
        </dd>
      </dl>

      <dl class="idl" title="dictionary MediaTrackConstraints">
        <dt>MediaTrackConstraintSet? mandatory = null</dt>

        <dd>
          <p class="issue">Provide definition of mandatory constraints here.</p>
        </dd>

        <dt>MediaTrackConstraint[]? _optional = null</dt>

        <dd>
          <p class="issue">Provide definition of optional constraints here.</p>
        </dd>
      </dl>

      <p>A MediaTrackConstraintSet is a dictionary containing one or more
      key-value pairs, where each key MUST be a valid registered constraint
      name in the IANA-hosted RTCWeb Media Constraints registry
      [[!RTCWEB-CONSTRAINTS]] and its value SHOULD be as defined in the
      associated reference(s) given in the registry.</p>

      <p>A MediaTrackConstraint is a dictionary containing exactly one
      key-value pair, where the key MUST be a valid registered constraint name
      in the IANA-hosted RTCWeb Media Constraints registry
      [[!RTCWEB-CONSTRAINTS]] and the value SHOULD be as defined in the
      associated reference(s) given in the registry.</p>

      <div class="note">
        <p>Example MediaTrackConstraints value:</p>
 
<pre>
{
  <code>mandatory</code>: {
    width: { min: 640 },
    height: { min: 480 }
  },
  <code>optional</code>: [
    { width: 650 },
    { width: { min: 650 }},
    { frameRate: 60 },
    { width: { max: 800 }},
    { facingMode: "user" }
  ]
}                                
</pre>
      </div>

    </section>

    <section>
      <h2>NavigatorUserMediaSuccessCallback</h2>

      <dl class="idl" title=
      "callback NavigatorUserMediaSuccessCallback = void">
        <dt>MediaStream stream</dt>

        <dd><p class="issue">Add explanation of handleEvent</p></dd>
      </dl>
    </section>

    <section>
      <h2>NavigatorUserMediaError and NavigatorUserMediaErrorCallback</h2>

      <dl class="idl" title=
      "[NoInterfaceObject] interface NavigatorUserMediaError : DOMError">

          <dt>readonly attribute DOMString? constraintName</dt>

          <dd>
            <p>This attribute is only used for some types of errors. For <code>
            <a>NavigatorUserMediaError</a></code> with a name of
            <code>ConstraintNotSatisfiedError</code>, this attribute MUST be set
            to the name of the constraint that caused the error.</p>
        </dd>
          
      </dl>

      <div class="note">
        <p>Ask the DOM team to extend their list with the following errors.</p>

        <ul>
          <li>PermissionDeniedError: User denied permission for scripts from
          this origin to access the media device.</li>

          <li>ConstraintNotSatisfiedError: One of the mandatory constraints
          could not be satisfied.</li>
        </ul>
      </div>
            
      <dl class="idl" title="callback NavigatorUserMediaErrorCallback = void">
        <dt>NavigatorUserMediaError error</dt>

        <dd><p class="issue">Add explanation of handleEvent</p></dd>
      </dl>
    </section>

    <section class="informative">
      <h2>Implementation Suggestions</h2>

      <div class="practice">
        <span id="resource-reservation" class="practicelab">Resource
        reservation</span>

        <p class="practicedesc">The user agent is encouraged to reserve
        resources when it has determined that a given call to <a href=
        "#dom-navigator-getusermedia">getUserMedia()</a> will succeed. It is
        preferable to reserve the resource prior to invoking the success
        callback provided by the web page. Subsequent calls to <a href=
        "#dom-navigator-getusermedia">getUserMedia()</a> (in this page or any
        other) should treat the resource that was previously allocated, as well
        as resources held by other applications, as busy. Resources marked as
        busy should not be provided as sources to the current web page, unless
        specified by the user. Optionally, the user agent may choose to provide
        a stream sourced from a busy source but only to a page whose origin
        matches the owner of the original stream that is keeping the source
        busy.</p>

        <p class="practicedesc">This document recommends that in the permission
        grant dialog or device selection interace (if one is present), the user
        be allowed to select any available hardware as a source for the stream
        requested by the page (provided the resource is able to fulfill
        mandatory constraints, if any were specified), in addition to the
        ability to substitute a video or audio source with local files and
        other media. A file picker may be used to provide this functionality to
        the user.</p>

        <p class="practicedesc">This document also recommends that the user be
        shown all resources that are currently busy as a result of prior calls
        to <a href="#dom-navigator-getusermedia">getUserMedia()</a> (in this
        page or any other page that is still alive) and be allowed to terminate
        that stream and utilize the resource for the current page instead. If
        possible in the current operating environment, it is also suggested
        that resources currently held by other applications be presented and
        treated in the same manner. If the user chooses this option, the track
        corresponding to the resource that was provided to the page whose
        stream was affected must be removed.</p>
      </div>

      <div class="practice">
        <span id="handling-devices" class="practicelab">Handling multiple
        devices</span>

        <p class="practicedesc">A <a>MediaStream</a> may contain more than one
        video and audio track. This makes it possible to include video from two
        or more webcams in a single stream object, for example. However, the
        current API does not allow a page to express a need for multiple video
        streams from independent sources.</p>

        <p class="practicedesc">It is recommended for multiple
        calls to <a href="#dom-navigator-getusermedia">getUserMedia()</a> from
        the same page be allowed as a way for pages to request multiple,
        discrete, video or audio streams.</p>

        <p class="practicedesc">A single call to
        <a href="#dom-navigator-getusermedia">getUserMedia()</a> will always
        return a stream with either zero or one audio tracks, and either zero or
        one video tracks. If a script calls
        <a href="#dom-navigator-getusermedia">getUserMedia()</a> multiple times
        before reaching a stable state, this document advises the UI designer
        that the permission dialogs should be merged, so that the user can give
        permission for the use of multiple cameras and/or media sources in one
        dialog interaction. The constraints on each getUserMedia call can be
        used to decide which stream gets which media sources.</p>
      </div>
    </section>
  </section>
 <section id="constrainable-interface">
  	 <h2>Constrainable Interface</h2>
  	 <p>The Constrainable interface allows its consumers to inspect
  	 	and adjust the properties of the object that implements it. It is
  	 	broken out as a separate partial interface so that it can be used in
  	 	other specifications.  The core concept is that of a Capability,
  	 	which consists of a property or feature of an object and the set of its possible values, which
  	 	 may be specified either as a range or as an enumeration. For example,
  	 	 a camera might be capable of framerates (a property) between 20 and 50 frames
  	 	 per second (a range) and may be able to be positioned (a property) facing towards
  	 	 the user, away from the user, or to the left or right of the user
  	 	 (an enumerated set.)  The application can examine a Constrainable object's
  	 	 set of Capabilities via the <code>capabilities</code> attribute.</p>
  	 	 <p>The application can select the (range of) values it wants for a
  	 	 	Capability by means of a Constraint and the <code>applyConstraints()</code>
  	 	 	method.  A Constraint consists of the name of the property,
  	 	 	plus the desired value (or a range of desired values.)  For example,
  	 	 	the application may set a Constraint stating that the framerate of a camera
  	 	 	be between 30 and 40 frames per second (a range) or that it wants the camera to be
  	 	 	facing the user (a specific value).  Constraints can be mandatory or optional. 
  	 	 	In the case of optional Constraints, the UA MUST consider the
  	 	 	Constraints in the order in which they are specified, and MUST try to
  	 	 	satisfy each one, but MAY ignore
  	 	 	a Constraint if it cannot satisfy it.  In the case of mandatory Constraints,
  	 	 	the MUST try to satisfy all of them, and MUST call the <code>errorCallback</code>
  	 	 	if it cannot do so.  For example, suppose that an application applies
  	 	 	three Constraints, stating that the video aspect ratio should be 3 to 2
  	 	 	(height to width), that the height should be 600 and that the width
  	 	 	should  be 500.  Since these constraints interact with each other (the aspect
  	 	 	ratio affects the possible values for height and width, and vice-versa) it is impossible to satisfy all three
  	 	 	constraints, so if all the Constraints are mandatory, the UA will call the
  	 	 	<code>errorCallback</code>.  However if any one of the
  	 	 	Constraints is optional, the other two can be satisified, so the UA
  	 	 	will satisfy the two mandatory ones, silently ignore the optional one,
  	 	 	and call the <code>successCallback.</code>
  	 	</p>
  	 	<p>The ordering of optional constraints is significant.  In the example
  	 		in the previous paragraph, suppose that aspect ratio constraint
  	 		is mandatory and that the height and width constraints are optional.
  	 		If the height constraint is specified first, then it will be satisfied
  	 		and the width constraint will be ignored.  Thus the height will be set to 600
  	 		and the the width will be set to 400.  On the other hand, if width is specified before height, the width
  	 		constraint will be satisfied and the height constraint will be ignored,
  	 		resulting in width of 500 and height of 750.  (Note that the mandatory
  	 		aspect ratio constraint is enforced in both cases.)  The UA will attempt
  	 		to satisfy as many optional constraints as it can, even if some of them cannot
  	 		be satisfied and must therefore be ignored.  Application authors can therefore
  	 		implement a backoff strategy by specifying multiple optional constraints
  	 		for the same property.  For example, an application might specify
  	 		three optional constraints, the first asking for a framerate greater than
  	 		500, the second asking for a framerate greater than 400, and the third
  	 		asking for one greater than 300.  If the UA is capable of setting a framerate
  	 		greater than 500, it will (and the subsequent two constraints will be trivially
  	 		satisifed.)  However, if the UA cannot set the framerate above 500, it will
  	 		ignore that constraint and attempt to set the framerate above 400. If that fails,
  	 		it will then try to set it above 300.  If the UA cannot satisfy any of the
  	 		three constraints, it will set the framerate to any value it can get.  If the
  	 		developer wanted to insist on 300 as a lower bound, he could make that a mandatory
  	 		constraint.  In that case, the UA would fail altogether if it couldn't get
  	 		a value over 300, but would choose a value over 500 if possible, then
  	 		try for a value over 400.  
  	 	 	An application may inspect the set of Constraints currently in effect
  	 	 	via the <code>constraints</code> attribute. </p>
  	 	 		<p>The specific value that the UA chooses for a Capability is
  	 	 			referred to as a Setting.  For example, if the application applies
  	 	 			a Constraint that the framerate must be at least 30 frames per second,
  	 	 			and no greater than 40, the Setting can be any intermediate value, e.g.,
  	 	 			32, 35, or 37 frames per second.  The application can query the current
  	 	 			settings of the object's Capabilities via the <code>settings</code> attribute.</p>
    	 <section>
  	 	<h2>Interface Definition</h2>
  	 	     <dl class="idl" title="[NoInterfaceObject] interface Constrainable">
  	 	     	         <dt>readonly attribute Capabilities capabilities()</dt>

          <dd>
            <p>Contains the dictionary of the capabilities that the object
            	supports. Note that it is possible that the underlying hardware       
             may not
            exactly map to the range defined in the specification.  In this
            case, an
            implementation <em title="should"
            class="rfc2119">should</em> make a reasonable attempt to
            translate and scale the hardware's setting onto the mapping
            provided by the relevant specification. </p>

            <div class="note">
              <p>An example of the user agent providing an alternative
              mapping: if a source supports a hypothetical fluxCapacitance
              capability that is defined to be the range
              from -10 (min) to 10 (max), but the source's (hardware
              setting) for fluxCapacitance only supports values of "off"
              "medium" and "full", then the user agent should map the
              range value of -10 to "off", 10 should map to "full", and
              0 should map to "medium". Constraints imposing a strict
              value of 3 will cause the user agent to attempt to set the
              value of "medium" on the hardware, and return a
              fluxCapacitance  of 0, the closest supported
              setting. No error event is raised in this
              scenario.</p>
            </div>
            <div class="issue">What about the case where the object uses
            	the same units as the specification, but supports only a sub-range
            	of the specified values?  What about an object whose fluxCapacitance
            	range is only -5 to 5?  Should it map those to -10 to 10, or leave
            	them as they are?   </div>

          </dd>
        <dt>readonly attribute Constraints constraints</dt>

        <dd>
          <p>Constains all the <code>Constraints</code> that were  
          	applied to the object in the last succesfull call of <code>applyConstraints()</code>. 
          	The list MUST contain only the constraints that were successfully applied,
          	and MUST maintain the order that they were specified in. </p>

          <p>If no mandatory constraints have been defined,
          the <code>mandatory</code> field will not be present (it will be
          undefined). If no optional constraints have been defined,
          the <code>optional</code> field will not be present (it will be
          undefined). If neither optional, nor mandatory constraints have been
          created, the value will be <code>null</code>.</p>
        
        </dd>
        	
          <dt>readonly attribute Settings settings()</dt>

          <dd>
            Contains the current settings of all the properties
            of the object, whether they are platform defaults or have been
            set by <code>applyConstraints()</code>.  Note that the actual setting
            of a property MUST be a single value.
          </dd>
        <dt> attribute EventHandler onoverconstrained</dt>

        <dd>This event handler, of type <code><a href=
        "#event-constrainable-overconstrained">overconstrained</a></code>, MUST
        be supported by all objects implementing the <code>
        <a>Constrainable</a></code> interface.  The UA MUST raise the 
        	<code>overconstrained</code> event if changing circumstances at runtime
        	result in the currently valid mandatory constraints no longer being satisfied.
        	The conditions under which this might happen are platform- and application-specific.
        	For example, the user might physically manipulate a camera in a way that
        	made it impossible to provide a resolution that satisified the constraints.  
        	</dd>


 
          
        <dt>void applyConstraints()</dt>

        <dd>
          <dl class="parameters">
            <dt>Constraints constraints</dt>
            <dd>A new constraint structure to apply to this object.</dd>
            <dt>VoidFunction successCallback</dt>
            <dd>Called if all mandatory constraints can be satisfied.</dd>
        <dt>ConstraintErrorCallback errorCallback</dt>
      <dd>Called if one or more mandatory constraints cannot be satisified.</dd>
          </dl>
          <p>The algorithm for applying constraints is stated below.
          	Here are some preliminary definitions that are used in the
          	statement of the algorithm:
          	<ul> 
          		<li>
          	A sequence of values for the properties of an object O satisfy
          	 constraint set C if each value a) is in the set of supported values specified by the corresponding
          	Capability of O, and b) is in the set specified by any constraints
          	in C that apply to that property, and c) there is no constraint in C that
          	does not correspond to a Capability in O. (Note that although this definition ignores
          	the difference between mandatory and optional constraints, the algorithm
          	below distinguishes between them.) </li>
          	<li> A set of constraints C can be satisifed
          	by an object O if it is possible to choose a sequence of values for the
          	properties of O that satisfy  C. </li>
          	<li>To apply a set of constraints
          	C to object O is to choose such a sequence of values that satisfy C and assign them as the 
          	settings for the properties of O.   </li>
          	</ul> 
          <p>When <code>applyConstraints</code> is called, the UA MUST queue a task
          to run the following steps:</p>
          <ol>
          
          	<li>let <var>desiredConstraints</var> be the argument to this function.
          		Each constraint MUST specify one or more values (or a range of values)
          		for its property.  
          		A property MAY appear more than once in the list of optional constraints.</li>
          			<li>Let <var>newConstraints</var> be an initially empty set
          			of constraints</li>
          		<li>Let <var>object</var> be the Constrainable object on which 
          			this method was called.  Let <var>copy</var> be an unconstrained copy of 
          			<var>object</var> (i.e., <var>copy</var> should behave
          			as if it were <var>object</var> with all constraints removed.) </li>
          	<li>If the mandatory constraints in <var>desiredConstraints</var> is
          		cannot be satisifed by <var>copy</var>, call the <code>errorCallback</code>, passing 
          		it a list of the mandatory constraints that could not be
          satisfied, and return. (Note that there may be more than one way of selecting
          the set of constraints that were not satisfied.)  <code>existingConstraints</code> remain
          in effect on <var>object</var> in this case.
          		</li>
          		<li>Otherwise add the mandatory constraints to <var>newConstraints</var></li>
          		<li>Iterate over the optional constraints in <var>desiredConstraints</var>
          			in the order in which they were specified.  For each constraint,if it and <var>newConstraints</var> together can be satisfied
          			by <var>copy</var>, add it to <var>newConstraints</var>.
          			Otherwise, ignore it. </li>
          			
          	<li>In a single operation, remove all existing constraints from <var>object</var>,
          		apply <var>newConstraints</var>, set the value of the <code>constraints</code>
          		attribute to <var>newConstraints</var>, and fire the <code>successCallback</code>
          		passing it <var>newConstraints</var> as its argument. Note: the UA
          		MAY modify the  values of one or more properties of <var>object</var>
          		at any time, as long as the resulting set of values satisfy the current set of
          		constraints.  
          		  </li>
          	</ol>
          	
         
        </dd>


      </dl>
  <section>
  	<h3>applyConstraints Failure Callback</h3>
      <section>

  	<section>
  	<h4>ConstraintError</h4>
 <dl class="idl" title="[NoInterfaceObject] interface ConstraintError">
 
          <dt>readonly attribute Constraints constraintNames</dt>

          <dd>Contains the set of mandatory constraints that could not
          	be satisified. The <code>optional</code> field in this 
          	object will be undefined.</dd>
          
      </dl>
      </section>
      <section>
<h4>ConstraintErrorCallback</h4>      
<dl class="idl" title="callback ConstraintErrorCallback = void">
        <dt>ConstraintError error</dt>

        <dd>An object holding the mandatory constraints that could not be satisfied.</dd>
      </dl>
      
  </section>
</section>     
      </section>
    <section>
      <h2>Capabilities, Constraints, and Settings</h2>
      
      <section id="registry">
      	<h3>The Property Registry</h3>
      	<p>For each class/interface that implements Constrainable, there MUST be a 
      		corresponding registry that defines the constrainable properties of that class
      		of object.  The registry entries MUST contain the name of each property along
      		with its set of legal values.  The registry for MediaStreamTrack is defined
      		<a href="#sec-constraints"> below</a>.
      		The syntax for the specification of
      		the set of legal values depends on the type of the values.  We define
      		three types here: boolean values, min-max ranges, and enumerated
      		lists of values.  Boolean values are built into JavaScript, the other
      		two types are defined below: </p>
 <section>     
 	   <h3>PropertyValueRange and PropertyValueList</h3>		
        <dl class="idl" title="dictionary PropertyValueRange">
          <dt>any max</dt>
        <dd>The maximum legal value of this property. 
          <p>The type of this value is specific to the object
          	and property in question.</p>
        
        </dd>

        <dt>any min</dt>
        <dd>The minimum value of this Property. 
          <p>The type of this value is specific to the object
          	and property in question.</p>
   
        </dd>

      </dl>
      
             <dl class="idl" title="typedef sequence<DOMString> PropertyValueList">
             	</dl>
        <p>PropertyValueLists are just an array of
        supported <code>DOMString</code> values.</p>
        	
  </section>
  
   	
   	<div class="issue">
   		<p>Should we allow registries to define new or different syntaxes for
   			capabilities?  For example could a registry introduce a new Capability
   			that had a min, a max, and a step value?</p></div>
      	</section>
      	
      	 <div class="issue">
   	<p>Should we allow the use of multiple registries?  For example, a spec
   		might define a registry of Capabilities, and an implementation might
   		define extensions.  In that case, we could think of the implementation as
   		having its own registry, and the final set of Capabilities as being the 
   		union of the two.</p>
   	</div>
      
      <section id="capabilities">
      	<h3>Capabilities</h3>
      	  <p> Capabilities a dictionary containing one or 
       	more key-value pairs, where each key MUST be a constrainable property
       	defined in the associated registry, and each value SHOULD be a subset
       	of the set of values defined for that property in the registry.  The exact syntax of the
       	value expression depends on the type of the property.  The Capabilities
       	dictionary specifies the subset of the 
       	constrainable properties and values from the registry that the UA supports. 
       	Note that a UA MAY support only a subset of the properties 
       	that are defined in the registry,  and
       	MAY support a subset of the set values for those properties that it does support.  
  </p>   	
      	</section>
      	
     <section id="settings">
     	<h3>Settings</h3></section>
   <p>  		Settings is a dictionary containing one or more key-value pairs.  It 
   	MUST contain each key returned in <code>capabilities()</code>.  There MUST
   	be a single value for each key and the value MUST a member of the set defined
   	for that property by <code>capabilities()</code>.  Thus the <code>Settings</code> 
    dictionary contains the actual values that the UA has chosen for the object's Capabilities.
  </p>   		
     <section id="Constraints">
     	<h3>Constraints</h3>
     		
     		  <dl class="idl" title="dictionary Constraints">
        <dt><a href="#constraintset">ConstraintSet?</a> mandatory</dt>

        <dd>
          <p>The set of Constraints that the UA MUST satisfy or else
          	call the <code>errorCallback</code>.  Note that a given property
          	name may occur only once in this set.</p>
        </dd>

        <dt>Constraint[] optional</dt>

        <dd>
          <p>The set of Constraints that the UA SHOULD try to satisfy
          	but MAY ignore if they cannot be satisified.  The order
          	of these constraints is significant.  In particular, when they are passed
          	as an argument to <code>applyConstraints</code>, the UA MUST
          	try to satisfy them in the order that is specified.  Thus
          	if optional constraints C1 and C2 can be satisfied individually, but
          	not together, then whichever of C1 and C2 is first in this list
          	will be satisfied, and the other will not. The UA MUST attempt
          	to satisfy all optional constraints in the list, even if some
          	cannot be satisfied. Thus, in the preceeding example, if 
          	optional constraint C3 is specified after C1 and C2, the UA will 
          	attempt to satisfy C3 even though C2 cannot be satisified. 
          	Note that a given property name may occur multiple times in this set. </p>
        </dd>
      </dl>


       <p>Each entry in the <a href="constraintset">ConstraintSet</a>
       	and <a href="constraint">Constraint</a> dictionaries 
       	corresponds to a property
       	and specifies a subset of its legal values.  Applying a constraint
       	instructs that UA to restrict the setting of the corresponding Capability to that
       	value or range of values.  A given property MAY occur both 
       	in the mandatory and the optional constraints list, and MAY occur
       	more than once in the optional constraints list.</p>
  
 
 <section id="constraintset"> 
 	<h4>ConstraintSet</h4>   
      <p> 	
       	A ConstraintSet is a dictionary containing one or 
       	more key-value pairs, where each key MUST be a constrainable property
       	defined in the associated registry, and each value SHOULD be a subset
       	of the set of values defined for that property in the registry.  The exact syntax of the
       	value expression depends on the type of the property.
       	 	</p>
</section>

<section id="constraint">
	<h4>Constraint</h4>
<p>
A Constraint is a dictionary containing exactly one 
key-value pair, where the key MUST be a constrainable property
       	defined in the associated registry, and the value SHOULD be a subset
       	of the set of values defined for that property in the registry.  The exact syntax of the
       	value expression depends on the type of the property.
</p>
</section>
</section>  
</section>
 </section>	
</section>
      
 
  <section>
    <h2>Examples</h2>

    <div>
      <p>This sample code exposes a button. When clicked, the button is
      disabled and the user is prompted to offer a stream. The user can cause
      the button to be re-enabled by providing a stream (e.g., giving the page
      access to the local camera) and then disabling the stream (e.g., revoking
      that access).</p>
      <pre class="example sh_javascript">
&lt;input type="button" value="Start" onclick="start()" id="startBtn"&gt;
&lt;script&gt;
 var startBtn = document.getElementById('startBtn');
 function start() {
   navigator.getUserMedia({audio:true, video:true}, gotStream, logError);
   startBtn.disabled = true;
 }
 function gotStream(stream) {
   stream.oninactive = function () {
     startBtn.disabled = false;
   };
 }
 function logError(error) {
   log(error.name + ": " + error.message);
 }
&lt;/script&gt; 
</pre>
    </div><!-- Put back when we define MediaStreamRecorder
    <div>
      <p>This example allows people to record a short audio message and upload
      it to the server. This example even shows rudimentary error handling.</p>
      <pre class='example sh_javascript'>
&lt;input type="button" value="⚫" onclick="msgRecord()" id="recBtn"&gt;
&lt;input type="button" value="◼" onclick="msgStop()" id="stopBtn" disabled&gt;
&lt;p id="status"&gt;To start recording, press the ⚫ button.&lt;/p&gt;
&lt;script&gt;
 var recBtn = document.getElementById('recBtn');
 var stopBtn = document.getElementById('stopBtn');
 function report(s) {
   document.getElementById('status').textContent = s;
 }
 function msgRecord() {
   report('Attempting to access microphone...');
   navigator.getUserMedia({audio:true}, gotStream, noStream);
   recBtn.disabled = true;
 }
 var msgStream, msgStreamRecorder;
 function gotStream(stream) {
   report('Recording... To stop, press to ◼ button.');
   msgStream = stream;
   msgStreamRecorder = stream.record();
   stopBtn.disabled = false;
   stream.oninactive = function () {
     msgStop();     
   }
 }
 function msgStop() {
   report('Creating file...');
   stopBtn.disabled = true;
   msgStream.oninactive = null;
   msgStream.stop();
   msgStreamRecorder.getRecordedData(msgSave);
 }
 function msgSave(blob) {
   report('Uploading file...');
   var x = new XMLHttpRequest();
   x.open('POST', 'uploadMessage');
   x.send(blob);
   x.onload = function () {
     report('Done! To record a new message, press the ⚫ button.');
     recBtn.disabled = false;
   };
   x.onerror = function () {
     report('Failed to upload message. To try recording a message again, press the ⚫ button.');
     recBtn.disabled = false;
   };
 }
 function noStream() {
   report('Could not obtain access to your microphone. To try again, press the ⚫ button.');
   recBtn.disabled = false;
 }
&lt;/script&gt;
</pre>
    </div>-->

    <div>
      <p>This example allows people to take photos of themselves from
      the local video camera.  Note that the forthcoming Image Capture
      specification may provide a simpler way to accomplish this.</p>
      <pre class="example sh_javascript">
&lt;article&gt;
 &lt;style scoped&gt;
  video { transform: scaleX(-1); }
  p { text-align: center; }
 &lt;/style&gt;
 &lt;h1&gt;Snapshot Kiosk&lt;/h1&gt;
 &lt;section id="splash"&gt;
  &lt;p id="errorMessage"&gt;Loading...&lt;/p&gt;
 &lt;/section&gt;
 &lt;section id="app" hidden&gt;
  &lt;p&gt;&lt;video id="monitor" autoplay&gt;&lt;/video&gt; &lt;canvas id="photo"&gt;&lt;/canvas&gt;
  &lt;p&gt;&lt;input type=button value="&amp;#x1F4F7;" onclick="snapshot()"&gt;
 &lt;/section&gt;
 &lt;script&gt;
  navigator.getUserMedia({video:true}, gotStream, noStream);
  var video = document.getElementById('monitor');
  var canvas = document.getElementById('photo');
  function gotStream(stream) {
    video.src = URL.createObjectURL(stream);
    stream.oninactive = noStream;
    video.onloadedmetadata = function () {
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      document.getElementById('splash').hidden = true;
      document.getElementById('app').hidden = false;
    };
  }
  function noStream() {
    document.getElementById('errorMessage').textContent = 'No camera available.';
  }
  function snapshot() {
    canvas.getContext('2d').drawImage(video, 0, 0);
  }
 &lt;/script&gt;
&lt;/article&gt;
</pre>
    </div>
  </section>

  <section>
    <h1 id="sec-iana">IANA Registrations</h1>

    <section>
      <h2 id="sec-constraints">Constraint Registrations</h2>

      <p>IANA is requested to register the following constraints as specified
      in [[!RTCWEB-CONSTRAINTS]]:</p>

      <div class="note">
          <p><strong>Note: </strong>The following specific list(s) of
          constraints DOES NOT REFLECT CONSENSUS.  Many constraints
          beyond these have been proposed, and the ones listed do not
          have universal support.  The ones below are included ****
          ONLY **** to provide a starting point so we can see concrete
          examples of what real constraints might look like.  Along
          those lines, there was an attempt to include constraints of
          a variety of types so sample type definitions could be
          included as well (e.g., DOMString, MinMaxConstraint).</p>
      </div>
 
      <p>The following constraint names are defined to apply to both <code><a>VideoStreamTrack</a></code> and <code><a>AudioStreamTrack</a></code> objects:</p>

      <table class="simple">
        <thead>
          <tr>
            <th>Constraint Name</th>
            <th>Values</th>
            <th>Notes</th>
          </tr>
        </thead>
        <tbody>
          <tr id="def-constraint-sourceType">
            <td>sourceType</td>
            <td><a><code>SourceTypeEnum</code></a></td>
            <td>Constrain the video or audio source to an exact value from the set of enumerated-type values of the <a><code>SourceTypeEnum</code></a>.</td>
          </tr>
          <tr id="def-constraint-sourceId">
            <td>sourceId</td>
            <td>DOMString</td>
            <td>Constrain the video or audio source to an exact source identifier value.</td>
          </tr>

          <tr id="def-constraint-noaccess">
            <td>noaccess</td>
            <td>boolean</td>
            <td>Prevent the stream from being applied to an element which is readable by the JS.</td>
          </tr>

          <tr id="def-constraint-peerIdentity">
            <td>peerIdentity</td>
            <td>DOMString</td>
            <td>Prevent the stream from being applied to an element which is readable by the JS. Require that any PeerConnections to which the stream is added match the provided identity.</td>
          </tr>

        </tbody>
      </table>

      <p>The following constraint names are defined to apply only to <code><a>VideoStreamTrack</a></code> objects:</p>

      <table class="simple">
        <thead>
          <tr>
            <th>Constraint Name</th>
            <th>Values</th>
            <th>Notes</th>
          </tr>
        </thead>
        <tbody>
          <tr id="def-constraint-width">
            <td>width</td>
            <td>unsigned long or
              <a><code>MinMaxConstraint</code></a>
            </td>
            <td>Constrain the video source to the exact desired width or width range.</td>
          </tr>
          <tr id="def-constraint-height">
            <td>height</td>
            <td>unsigned long or <a><code>MinMaxConstraint</code></a></td>
            <td>Constrain the video source to the exact desired height or height range.</td>
          </tr>
          <tr id="def-constraint-frameRate">
            <td>frameRate</td>
            <td>float or <a><code>MinMaxConstraint</code></a></td>
            <td>Constrain the video source to the exact desired frame rate (fps) or frameRate range.</td>
          </tr>
          <tr id="def-constraint-aspect">
            <td>aspectRatio</td>
            <td>float or <a><code>MinMaxConstraint</code></a></td>
            <td>Constrain the video source to the exact desired aspect
            ratio represented as floating point number rounded to 10
            decimal places, representing the width in pixels divided by
            the height in pixels.</td>
          </tr>
          <tr id="def-constraint-facingMode">
            <td>facingMode</td>
            <td><code><a>VideoFacingModeEnum</a></code></td>
            <td>Constrain the video source to an exact value from the set of enumerated-type values of the <code><a>VideoFacingModeEnum</a></code>.</td>
          </tr>
        </tbody>
      </table>

      <p>The following constraint names are defined to apply only to <code><a>AudioStreamTrack</a></code> objects:</p>
                
      <table class="simple">
        <thead>
          <tr>
            <th>Constraint Name</th>
            <th>Values</th>
            <th>Notes</th>
          </tr>
        </thead>
        <tbody>
          <tr id="def-constraint-volume">
            <td>volume</td>
            <td>unsigned long or <a><code>MinMaxConstraint</code></a></td>
            <td>Constrain the audio source to the exact desired volume or volume range.</td>
          </tr>
        </tbody>
      </table>

      <p>For constraints that accept ranges,
         the <code><a>MinMaxConstraint</a></code> dictionary is also
         defined. Note that the type of the value associated
         with <code>min</code> and <code>max</code> must be the same
         for both. The specific types associated with <code>min</code>
         and <code>max</code> are defined differently for each
         constraint name.</p>

      <dl class="idl" title="dictionary MinMaxConstraint">
        <dt>any max</dt>
        <dd>The related constraint's maximum allowed value.</dd>
        <dt>any min</dt>
        <dd>The related constraint's minimum allowed value.</dd>
      </dl>

      <dl>
                
                <!-- please leaves this just commented out in the file for now - Cullen

      <dt> EchoCancelation </dt>

      <dd> <p> This is a enum type constraint that can take the values "true"
        and "false". The default is a non mandatory "true". </p>

        <p> When one or more audio streams is being played in the proceses of
        varios microphones, it is often desirable to attempt to remove the sound
        being played from the input signals recorded by the microphones. This is
        referred to echo cancelation. There are cases where it is not needed and
        it is desirable to turn it off so that no audio artifacts are
        introduced. This constraint allows the application to control this
        behavior. </p>
      </dd>

      <dt> CaptureAudio </dt>

      <dd> <p> This is a enum type constraint that can take the values "true"
        and "false". The default is a non mandatory "true". </p>

        <p> Indicates that application would like to capture audio input from a
        microphone. </p>
      </dd>

      <dt> CaptureVideo </dt>

      <dd> <p> This is a enum type constraint that can take the values "true"
        and "false". The default is a non mandatory "true". </p>

        <p> Indicates that application would like to capture video input from a
        camera. </p>
      </dd>

      <dt> CaptureImage </dt>

      <dd> <p> This is a enum type constraint that can take the values "true"
        and "false". The default is a non mandatory "true". </p>

        <p> Indicates that application would like to capture an single image from a
        camera. </p>
      </dd>


        <dt> EnableSecureMedia </dt>

      <dd> <p> This is a enum type constraint that can take the values "true"
        and "false". The default is a non mandatory "false". </p>

        <p> Indicates that application would like the browser to keep the media
        secure. This means that the media will not be a available to JavaScript
        application but is useful for cases where other objects will operate on
        the media stream. For some trusted application environments, the browser
        may enforce that this constraint is a mandatory "true". </p> </dd>

      -->
      </dl>
    </section>
  </section>

  <section>
    <h2>Change Log</h2>

    <p>This section will be removed before publication.</p>


      <!--
    <h2>To Do Items</h2>

    <p>-</p>
    -->


    <h2>Changes since August 24, 2013</h2>

    <ol>
      <li>Bug 22269: Renamed getSourceInfos() to getSources() and made the
      result async.</li>

      <li>Bug 22229: Editorial input</li>

      <li>Bug 22243: Clarify readonly track</li>

      <li>Bug 22259: Disabled mediastreamtrack and state of media element</li>

      <li>Bug 22226: Remove check of same source from MediaStream constructor
      algorithm</li>

      <li>Replaced ended with inactive for MediaStream (resolves bug 21618).
      </li>

      <li>Bug 22264: MediaStream.ended set to true on creation</li>

      <li>Bug 22272: Permission revokation via MediaStreamTrack.stop()</li>

      <li>Bug 22248: Relationship between MediaStreamTrack and HTML5
      VideoTrack/AudioTrack after MediaStream assignment</li>

      <li>Bug 22247: Setting loop attribute on a media element reading from a
      MediaStream</li>
    </ol>

    <h2>Changes since July 4, 2013</h2>

    <ol>
      <li>Bug 21967: Added paragraph on MediaStreamTrack enabled state and
      updated cloning algorithm.</li>

      <li>Bug 22210: Make getUserMedia() algorithm use all numbered items.</li>

      <li>Bug 22250: Fixed accidentally overridden error.</li>

      <li>Bug 22211: Added async error when no valid media type is requested.

      <li>Bug 22216: Made NavigatorUserMediaError extend DOMError.</li>

      <li>Bug 22249: Throw on attempts to set currentTime on media elements
      playing MediaStream objects.</li>

      <li>Bug 22246: Made media.buffered have length 0.</li>

      <li>Bug 22692: Updated media element to use HAVE_NOTHING state
      before media arrives on the played MediaStream and
      HAVE_ENOUGH_DATA as soon as media arrives.</li>
    </ol>

    <h2>May 29, 2013</h2>

    <ol>
      <li>Bug 22252: fixed usage of MUST in MediaStream() constructor
      description.</li>

      <li>Bug 22215: made MediaStream.ended readonly.</li>

      <li>Bug 21967: clarified MediaStreamTrack.enabled state initial value.
      </li>

      <li>Added aspectRatio constraint, capability, and state.</li>
      <li>Updated usage of MediaStreams in media elements.</li>
    </ol>

    <h2>May 15, 2013</h2>

    <ol>
      <li>Added explanatory section for constraints, capabilities, and
      states.</li>
      <li>Added VideoFacingModeEnum (including left and right options).</li>
      <li>Added getSourceInfos() and SourceInfo dictionary.</li>
      <li>Added isolated streams.</li>
    </ol>

    <h2>April 29, 2013</h2>

    <ol>
      <li>Removed remaining photo APIs and references (since we have a
      separate Image Capture Spec).</li>
    </ol>

    <h2>March 20, 2013</h2>

    <ol>
      <li> Added readonly and remote attributes to MediaStreamTrack</li>
      <li> Removed getConstraint(), setConstraint(), appendConstraint(), and prependConstraint().</li>
      <li> Added source states.  Added states() method on tracks.  Moved sourceType and sourceId to be states.</li>
      <li> Added source capabilities.  Added capabilities() method on tracks.</li>
      <li>Added clarifying text about MediaStreamTrack lifecycle and mediaflow.</li>
      <li>Made MediaStreamTrack cloning explicit.</li>
      <li>Removed takePhoto() and friends from VideoStreamTrack (we have a
      separate Image Capture Spec).</li>
      <li>Made getUserMedia() error callback mandatory.</li>
    </ol>


    <h2>December 12, 2012</h2>

    <ol>
      <li> Changed error code to be string instead of number.</li>
      <li> Added core of settings proposal allowing for constraint changes after stream/track creation.</li>
    </ol>

    
    <h2>November 15 2012</h2>

    <ol>
      <li>Introduced new representation of tracks in a stream
      (removed MediaStreamTrackList).</li>

      <li>Updated MediaStreamTrack.readyState to use an enum type (instad of
      unsigned short constants).</li>

      <li>Renamed MediaStream.label to MediaStream.id (the definition needs
      some more work).</li>
    </ol>

    <h2>October 1 2012</h2>

    <ol>
      <li>Limited the track kind values to "audio" and "video" only (could
      previously be user defined as well).</li>

      <li>Made MediaStream extend EventTarget.</li>

      <li>Simplified the MediaStream constructor.</li>
    </ol>

    <h2>June 23 2012</h2>

    <ol>
      <li>Rename title to "Media Capture and Streams".</li>

      <li>Update document to comply with HTML5.</li>

      <li>Update image describing a MediaStream.</li>

      <li>Add known issues and various other editorial changes.</li>
    </ol>

    <h2>June 22 2012</h2>

    <ol>
      <li>Update wording for constraints algorithm.</li>
    </ol>

    <h2>June 19 2012</h2>

    <ol>
      <li>Added "Media Streams as Media Elements section".</li>
    </ol>

    <h2>June 12 2012</h2>

    <ol>
      <li>Switch to respec v3.</li>
    </ol>

    <h2>June 5 2012</h2>

    <ol>
      <li>Added non-normative section "Implementation Suggestions".</li>

      <li>Removed stray whitespace.</li>
    </ol>

    <h2>June 1 2012</h2>

    <ol>
      <li>Added media constraint algorithm.</li>
    </ol>

    <h2>Apr 23 2012</h2>

    <ol>
      <li>Remove MediaStreamRecorder.</li>
    </ol>

    <h2>Apr 20 2012</h2>

    <ol>
      <li>Add definitions of MediaStreams and related objects.</li>
    </ol>

    <h2>Dec 21 2011</h2>

    <ol>
      <li>Changed to make wanted media opt in (rather than opt out). Minor
      edits.</li>
    </ol>

    <h2>Nov 29 2011</h2>

    <ol>
      <li>Changed examples to use MediaStreamOptions objects rather than
      strings. Minor edits.</li>
    </ol>

    <h2>Nov 15 2011</h2>

    <ol>
      <li>Removed MediaStream stuff. Refers to webrtc 1.0 spec for that part
      instead.</li>
    </ol>

    <h2>Nov 9 2011</h2>

    <ol>
      <li>Created first version by copying the webrtc spec and ripping out
      stuff. Put it on github.</li>
    </ol>
  </section>

  <section class="appendix">
    <h2>Acknowledgements</h2>
  </section>
x</body>
</html>
